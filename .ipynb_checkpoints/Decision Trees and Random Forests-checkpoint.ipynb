{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is an implementation of a decision tree and random forest for classification on the Titanic and Spam datasets. The decision tree calculates a split that maximizes information gain, and builds a tree structure maintaining class probabilities. Traversal stops when a class reaches a probability of 1.0, or we reach a specified maximum depth. The random forest implements the bagging ensemble method, training individual trees on random subsets of the data, then outputting the mode of all predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import genfromtxt\n",
    "import scipy.io\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "%matplotlib inline\n",
    "\n",
    "class Node:\n",
    "    \"\"\"\n",
    "    A single node in the decision tree:\n",
    "    \n",
    "    left: pointer to left subtree\n",
    "    right: pointer to right subtree\n",
    "    split_rule: A pair containing a feature and threshold to split on (f, t)\n",
    "    depth: The current depth of the node in the tree\n",
    "    probs: Probability of each class label at this node (only at leaves)\n",
    "    \"\"\"\n",
    "    def __init__(self, left, right, rule, depth, probs = None):\n",
    "        self.split_rule = rule\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.depth = depth\n",
    "        self.probs = probs\n",
    "        \n",
    "    def is_leaf(self):\n",
    "        return self.probs is not None # Only the leaf nodes will store probabilities\n",
    "    \n",
    "class DecisionTree:\n",
    "    \n",
    "    def __init__(self, features, classes):\n",
    "        self.classes = classes\n",
    "        self.class_indices = np.arange(len(classes))\n",
    "        self.features = features\n",
    "        \n",
    "    def LeafNode(self, depth, probs):\n",
    "        \"\"\"\n",
    "        Leaf node for the decision tree. Has no children or split rule, just \n",
    "        current depth and class probabilities.\n",
    "        \"\"\"\n",
    "        return Node(None, None, None, depth, probs)\n",
    "    \n",
    "    def calc_probs(self, y):\n",
    "        \"\"\"\n",
    "        Calculate the proportion of each class label within y.\n",
    "        \"\"\"\n",
    "        return np.array([np.mean([y == label * np.ones(len(y))]) for label in self.class_indices])\n",
    "        \n",
    "    def entropy(self, y):\n",
    "        \"\"\"\n",
    "        Calculates the entropy given all the labels\n",
    "        \"\"\"\n",
    "        return stats.entropy(self.calc_probs(y))\n",
    "\n",
    "    def information_gain(self, X, y, idx, thresh):\n",
    "        \"\"\"\n",
    "        Calculates information gain given a vector of features and a split threshold\n",
    "        \"\"\"\n",
    "        left, right = self.split(X, y, idx, thresh)\n",
    "        left_H = self.entropy(y[left]) if list(left) else 0\n",
    "        right_H = self.entropy(y[right]) if list(right) else 0\n",
    "        H_after = (len(left) * left_H + len(right) * right_H) / len(y)\n",
    "        return self.entropy(y) - H_after\n",
    "\n",
    "    def split(self, X, y, idx, thresh):\n",
    "        \"\"\"\n",
    "        Returns a split of the dataset given an index of the feature and\n",
    "        a threshold for it\n",
    "        \n",
    "        \"\"\"\n",
    "        left, right = [], []\n",
    "        f = self.features[idx]\n",
    "        for i in range(len(X)):\n",
    "            point = X[i]\n",
    "            comparison = lambda x,y : (x == y if f in [\"pclass\", \"sex\", \"embarked\"] else x < y)\n",
    "            if comparison(point[idx], thresh):\n",
    "                left.append(i)\n",
    "            else:\n",
    "                right.append(i)\n",
    "        return np.array(left), np.array(right)\n",
    "        \n",
    "    def segmenter(self, X, y):\n",
    "        \"\"\"\n",
    "        Compute entropy gain for all single-dimension splits,\n",
    "        return the feature and the threshold for the split that\n",
    "        has maximum gain\n",
    "        \"\"\"\n",
    "        best_gain = -float('inf')\n",
    "        best_pair = None\n",
    "        for i in range(len(self.features)):\n",
    "            thresholds = list(set(X[:,i]))\n",
    "            for threshold in thresholds:\n",
    "                curr_gain = self.information_gain(X, y, i, threshold)\n",
    "                if curr_gain > best_gain:\n",
    "                    best_pair = (i, threshold)\n",
    "                    best_gain = curr_gain\n",
    "        return best_pair\n",
    "             \n",
    "    def fit(self, X, y, max_depth):\n",
    "        \"\"\"\n",
    "        Fit the model to a training set using the grow_tree helper function.\n",
    "        \"\"\"\n",
    "        self.root = self.grow_tree(X, y, 0, max_depth)\n",
    "        \n",
    "    def grow_tree(self, X, y, curr_depth, max_depth):\n",
    "        probs = self.calc_probs(y)\n",
    "        feature, threshold = self.segmenter(X, y)\n",
    "        left, right = self.split(X, y, feature, threshold)\n",
    "        X_left = None if not list(left) else X[left]\n",
    "        y_left = None if not list(left) else y[left]\n",
    "        X_right = None if not list(right) else X[right]\n",
    "        y_right = None if not list(right) else y[right]\n",
    "        if 1.0 in probs or curr_depth == max_depth:\n",
    "            return self.LeafNode(curr_depth, probs)\n",
    "        if X_left is not None:\n",
    "            left_node = self.grow_tree(X_left, y_left, curr_depth + 1, max_depth)\n",
    "        else:\n",
    "            left_node = self.LeafNode(curr_depth + 1, probs)\n",
    "        if X_right is not None:\n",
    "            right_node = self.grow_tree(X_right, y_right, curr_depth + 1, max_depth)\n",
    "        else:\n",
    "            right_node = self.LeafNode(curr_depth + 1, probs)\n",
    "        return Node(left_node, right_node, (feature, threshold), curr_depth)\n",
    "   \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the labels for input data \n",
    "        \"\"\"\n",
    "        y = []\n",
    "        for point in X:\n",
    "            node = self.root\n",
    "            while node is not None and not node.is_leaf():\n",
    "                feature, threshold = node.split_rule\n",
    "                comparison = lambda x,y : (x == y if self.features[feature] in [\"pclass\", \"sex\", \"embarked\"] else x < y)\n",
    "                node = node.left if comparison(point[feature], threshold) else node.right\n",
    "            y.append(np.argmax(node.probs))\n",
    "        return np.array(y)\n",
    "                    \n",
    "    \"\"\"\n",
    "    Visualization method for the tree\n",
    "    \"\"\"    \n",
    "    def generateString(self, node):\n",
    "        if not node:\n",
    "            return \"\"\n",
    "        if node.is_leaf():\n",
    "            \n",
    "            output = str(dict(zip(self.classes, node.probs)))\n",
    "            \n",
    "            return \"\\t\" * node.depth + output\n",
    "        fidx, thresh = node.split_rule\n",
    "        return \"\\t\" * node.depth + f\"{self.features[fidx]}, {thresh}\\n\" \\\n",
    "             + \"\\t\" * node.left.depth \\\n",
    "             + self.generateString(node.left) \\\n",
    "             + \"\\t\" * node.right.depth \\\n",
    "             + self.generateString(node.right)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        \n",
    "        return self.generateString(self.root)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    \n",
    "    def __init__(self, features, classes, num_trees):\n",
    "        \"\"\"\n",
    "        Initialization of a random forest\n",
    "        \"\"\"\n",
    "        self.trees = np.array([DecisionTree(features, classes) for _ in range(num_trees)])\n",
    "    def fit(self, X, y, max_depth):\n",
    "        \"\"\"\n",
    "        Fit the model to a training set\n",
    "        \"\"\"\n",
    "        for tree in self.trees:\n",
    "            X_t, y_t = [], []\n",
    "            for _ in range(len(y)):\n",
    "                idx = np.random.randint(len(y))\n",
    "                X_t.append(X[idx])\n",
    "                y_t.append(y[idx])\n",
    "            \n",
    "            tree.fit(np.array(X_t), np.array(y_t), max_depth)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the labels for input data \n",
    "        \"\"\"\n",
    "        predictions = np.array([tree.predict(X) for tree in self.trees])\n",
    "        final_predictions = np.array([stats.mode(predictions[:, i])[0][0] for i in range(len(predictions[0]))])\n",
    "        return final_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perfomance Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will preprocess the data to encode categorical values and fill in missing values. Then, we will train our models and measure their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nprasad/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:34: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "/Users/nprasad/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:35: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n"
     ]
    }
   ],
   "source": [
    "# Check if s is a numerical value\n",
    "def is_numeric(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except (ValueError, TypeError):\n",
    "        return False\n",
    "# Preprocess the data by converting from strings to floats, and encoding categorical data with the LabelEncoder      \n",
    "def process_data(features, dataset):\n",
    "    for i in range(len(features)):\n",
    "            column = dataset[:,i]\n",
    "            for j in range(len(column)):\n",
    "                if column[j] == '':\n",
    "                    values = np.array([x for x in column if x != ''])\n",
    "                    if all(list(map(is_numeric, values))):\n",
    "                        values = values.astype(np.float64)\n",
    "                        column[j] = np.mean(values)\n",
    "            dataset[:,i] = column\n",
    "            # Label encoding for categorical features\n",
    "            le = LabelEncoder()\n",
    "            if not is_numeric(dataset[0,i]):\n",
    "                le.fit(dataset[:,i])\n",
    "                dataset[:,i] = le.transform(dataset[:,i])\n",
    "    \n",
    "    return dataset.astype(np.float64)\n",
    "\n",
    "\"\"\"\n",
    "Read in the datasets from given files and run preprocessing.\n",
    "\"\"\"\n",
    "def generate_data(dataset):\n",
    "    # The titanic dataset requires preprocessing to convert categorical data and fill in missing values\n",
    "    if dataset == \"titanic\":\n",
    "    # Load titanic data       \n",
    "        data = genfromtxt('titanic_training.csv', delimiter=',', dtype=None)\n",
    "        test_data = genfromtxt('titanic_testing_data.csv', delimiter=',', dtype=None)\n",
    "        y = data[1:, 0]\n",
    "        class_names = [\"Died\", \"Survived\"]\n",
    "        features = data[0].astype(np.str)\n",
    "        data = process_data(features, data[1:].astype(np.str))\n",
    "        test_features = test_data[0].astype(np.str)\n",
    "        test_data = process_data(test_features, test_data[1:].astype(np.str))\n",
    "        y = y.astype(np.str)\n",
    "        empty_indices = [i for i in range(len(y)) if y[i] == '']\n",
    "        # Remove the indices with empty data\n",
    "        for i in empty_indices:\n",
    "            data = np.delete(data,i,0)\n",
    "            y = np.delete(y,i)\n",
    "        y = y.astype(np.int)\n",
    "    # The spam dataset does not require the above preprocessing: simply load the data    \n",
    "    elif dataset == \"spam\":\n",
    "        features = [\n",
    "        \"pain\", \"private\", \"bank\", \"money\", \"drug\", \"spam\", \"prescription\",\n",
    "        \"creative\", \"height\", \"featured\", \"differ\", \"width\", \"other\",\n",
    "        \"energy\", \"business\", \"message\", \"volumes\", \"revision\", \"path\",\n",
    "        \"meter\", \"memo\", \"planning\", \"pleased\", \"record\", \"out\",\n",
    "        \"semicolon\", \"dollar\", \"sharp\", \"exclamation\", \"parenthesis\",\n",
    "        \"square_bracket\", \"ampersand\"\n",
    "        ]\n",
    "        assert len(features) == 32\n",
    "\n",
    "    # Load spam data\n",
    "        data = scipy.io.loadmat('spam_data.mat')\n",
    "        X = data['training_data']\n",
    "        y = np.squeeze(data['training_labels'])\n",
    "        test_data = data['test_data']\n",
    "        class_names = [\"Ham\", \"Spam\"]\n",
    "        data = X\n",
    "    return data, y, test_data, features, class_names\n",
    "         \n",
    "    \n",
    "\n",
    "titanic_X, titanic_y, titanic_test, titanic_features, titanic_classes = generate_data(\"titanic\")\n",
    "spam_X, spam_y, spam_test, spam_features, spam_classes = generate_data(\"spam\")\n",
    "titanic_X = np.delete(titanic_X,0,1)\n",
    "titanic_features = titanic_features[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we measure the performance of both models through training and validation accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and validate both models, outputting training and validation accuracies\n",
    "X_train_t, X_val_t, y_train_t, y_val_t = tts(titanic_X, titanic_y, test_size=0.8, random_state=42)\n",
    "X_train_s, X_val_s, y_train_s, y_val_s = tts(spam_X, spam_y, test_size=0.8, random_state=42)\n",
    "titanic_tree = DecisionTree(titanic_features, titanic_classes)\n",
    "titanic_forest = RandomForest(titanic_features, titanic_classes, 5)\n",
    "spam_tree = DecisionTree(spam_features, spam_classes)\n",
    "spam_forest = RandomForest(spam_features, spam_classes, 5)\n",
    "titanic_tree.fit(X_train_t, y_train_t, 10)\n",
    "titanic_forest.fit(X_train_t, y_train_t, 10)\n",
    "spam_tree.fit(X_train_s, y_train_s, 10)\n",
    "spam_forest.fit(X_train_s, y_train_t, 10)\n",
    "titanic_tree_pred_tr = titanic_tree.predict(X_train_t)\n",
    "titanic_tree_pred_va = titanic_tree.predict(X_val_t)\n",
    "spam_tree_pred_tr = spam_tree.predict(X_train_s)\n",
    "spam_tree_pred_va = spam_tree.predict(X_val_s)\n",
    "titanic_forest_pred_tr = titanic_forest.predict(X_train_t)\n",
    "titanic_forest_pred_va = titanic_forest.predict(X_val_t)\n",
    "spam_tree_forest_tr = spam_forest.predict(X_train_s)\n",
    "spam_tree_forest_va = spam_forest.predict(X_val_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy for Titanic with Decision Tree: 0.9547738693467337\n",
      "Validation accuracy for Titanic with Decision Tree: 0.74\n",
      "Training accuracy for Titanic with Random Forest: 0.9547738693467337\n",
      "Validation accuracy for Titanic with Random Forest: 0.72625\n",
      "Training accuracy for Spam with Decision Tree: 0.8558994197292069\n",
      "Validation accuracy for Spam with Decision Tree: 0.7982116964717255\n",
      "Training accuracy for Spam with Random Forest: 0.5793036750483559\n",
      "Validation accuracy for Spam with Random Forest: 0.5386660222329628\n"
     ]
    }
   ],
   "source": [
    "def calc_acc(pred, actual):\n",
    "    return np.mean(pred == actual)\n",
    "\n",
    "training_acc_titanic_tree = calc_acc(titanic_tree_pred_tr, y_train_t)\n",
    "validation_acc_titanic_tree = calc_acc(titanic_tree_pred_va, y_val_t)\n",
    "training_acc_titanic_forest = calc_acc(titanic_forest_pred_tr, y_train_t)\n",
    "validation_acc_titanic_forest = calc_acc(titanic_forest_pred_va, y_val_t)\n",
    "training_acc_spam_tree = calc_acc(spam_tree_pred_tr, y_train_s)\n",
    "validation_acc_spam_tree = calc_acc(spam_tree_pred_va, y_val_s)\n",
    "training_acc_spam_forest = calc_acc(spam_tree_forest_tr, y_train_s)\n",
    "validation_acc_spam_forest = calc_acc(spam_tree_forest_va, y_val_s)\n",
    "print(f\"Training accuracy for Titanic with Decision Tree: {training_acc_titanic_tree}\")\n",
    "print(f\"Validation accuracy for Titanic with Decision Tree: {validation_acc_titanic_tree}\")\n",
    "print(f\"Training accuracy for Titanic with Random Forest: {training_acc_titanic_forest}\")\n",
    "print(f\"Validation accuracy for Titanic with Random Forest: {validation_acc_titanic_forest}\")\n",
    "print(f\"Training accuracy for Spam with Decision Tree: {training_acc_spam_tree}\")\n",
    "print(f\"Validation accuracy for Spam with Decision Tree: {validation_acc_spam_tree}\")\n",
    "print(f\"Training accuracy for Spam with Random Forest: {training_acc_spam_forest}\")\n",
    "print(f\"Validation accuracy for Spam with Random Forest: {validation_acc_spam_forest}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we plot the validation error as a function of tree depth for both the decision tree and random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d65f6d6c4978>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_s\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mforest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0merrors_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-135c9565e004>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, max_depth)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mFit\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mto\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mset\u001b[0m \u001b[0musing\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgrow_tree\u001b[0m \u001b[0mhelper\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \"\"\"\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrow_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgrow_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-135c9565e004>\u001b[0m in \u001b[0;36mgrow_tree\u001b[0;34m(self, X, y, curr_depth, max_depth)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLeafNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX_left\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mleft_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrow_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_depth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mleft_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLeafNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_depth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-135c9565e004>\u001b[0m in \u001b[0;36mgrow_tree\u001b[0;34m(self, X, y, curr_depth, max_depth)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLeafNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX_left\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mleft_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrow_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_depth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mleft_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLeafNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_depth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-135c9565e004>\u001b[0m in \u001b[0;36mgrow_tree\u001b[0;34m(self, X, y, curr_depth, max_depth)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLeafNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX_left\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mleft_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrow_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_depth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mleft_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLeafNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_depth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-135c9565e004>\u001b[0m in \u001b[0;36mgrow_tree\u001b[0;34m(self, X, y, curr_depth, max_depth)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLeafNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX_left\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mleft_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrow_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_depth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mleft_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLeafNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_depth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-135c9565e004>\u001b[0m in \u001b[0;36mgrow_tree\u001b[0;34m(self, X, y, curr_depth, max_depth)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLeafNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX_left\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mleft_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrow_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_depth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mleft_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLeafNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_depth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-135c9565e004>\u001b[0m in \u001b[0;36mgrow_tree\u001b[0;34m(self, X, y, curr_depth, max_depth)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLeafNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX_left\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mleft_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrow_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_depth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mleft_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLeafNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_depth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-135c9565e004>\u001b[0m in \u001b[0;36mgrow_tree\u001b[0;34m(self, X, y, curr_depth, max_depth)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgrow_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_probs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegmenter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mX_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-135c9565e004>\u001b[0m in \u001b[0;36msegmenter\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mcurr_gain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minformation_gain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcurr_gain\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_gain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                     \u001b[0mbest_pair\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-135c9565e004>\u001b[0m in \u001b[0;36minformation_gain\u001b[0;34m(self, X, y, idx, thresh)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mCalculates\u001b[0m \u001b[0minformation\u001b[0m \u001b[0mgain\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0ma\u001b[0m \u001b[0mvector\u001b[0m \u001b[0mof\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0ma\u001b[0m \u001b[0msplit\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \"\"\"\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mleft_H\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mright_H\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-135c9565e004>\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, idx, thresh)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mcomparison\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"pclass\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sex\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"embarked\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mcomparison\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m                 \u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-135c9565e004>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mcomparison\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"pclass\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sex\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"embarked\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcomparison\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def error(y_pred, y):\n",
    "    return 1 - calc_acc(y_pred, y)\n",
    "\n",
    "X_train_s, X_val_s, y_train_s, y_val_s = tts(spam_X, spam_y, test_size=0.8, random_state=27)\n",
    "errors_tree = []\n",
    "errors_forest = []\n",
    "tree = DecisionTree(spam_features, spam_classes)\n",
    "forest = RandomForest(spam_features, spam_classes, 4)\n",
    "\n",
    "for i in range(1,10):\n",
    "    tree.fit(X_train_s, y_train_s,i)\n",
    "    forest.fit(X_train_s, y_train_s, i)\n",
    "    errors_tree.append(error(tree.predict(X_val_s), y_val_s))\n",
    "    errors_forest.append(error(forest.predict(X_val_s), y_val_s))\n",
    "    \n",
    "plt.plot(list(range(1,10)), errors_tree, label=\"Decision Tree\")\n",
    "plt.plot(list(range(1,10)), errors_forest, label=\"Random Forest\")\n",
    "plt.legend()\n",
    "plt.title(\"Validation Error on Spam Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample visualization of Decision Tree structure\n",
    "titanic = DecisionTree(titanic_features, titanic_classes)\n",
    "titanic.fit(titanic_X, titanic_y, 3)\n",
    "print(titanic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will generate our predictions on a test set, and write them to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write our results to CSV file\n",
    "def results_to_csv(y_test, name):\n",
    "    y_test = y_test.astype(int)\n",
    "    df = pd.DataFrame({'Category': y_test})\n",
    "    df.index += 1 # Ensures that the index starts at 1. \n",
    "    csv_name = name + '.csv'\n",
    "    df.to_csv(csv_name, index_label='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit decision tree and random forest to both datasets, then generate predictions\n",
    "tree_t = DecisionTree(titanic_features, titanic_classes)\n",
    "tree_s = DecisionTree(spam_features, spam_classes)\n",
    "forest_t = RandomForest(titanic_features, titanic_classes, 10)\n",
    "forest_s = RandomForest(spam_features, spam_classes, 10)\n",
    "tree_t.fit(titanic_X,titanic_y, 10)\n",
    "tree_s.fit(spam_X,spam_y, 3)\n",
    "forest_t.fit(titanic_X, titanic_y, 3)\n",
    "forest_s.fit(spam_X, spam_y,3)\n",
    "titanic_test_tree = tree_t.predict(titanic_test)\n",
    "spam_test_tree = tree_s.predict(spam_test)\n",
    "titanic_test_forest = forest_t.predict(titanic_test)\n",
    "spam_test_forest = forest_s.predict(spam_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a CSV file for each set of predictions\n",
    "results_to_csv(titanic_test_tree, \"titanic_tree\")\n",
    "results_to_csv(spam_test_tree, \"spam_tree\")\n",
    "results_to_csv(spam_test_forest, \"spam_forest\")\n",
    "results_to_csv(titanic_test_forest, \"titanic_forest\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
