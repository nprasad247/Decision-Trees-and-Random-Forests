{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is an implementation of a decision tree and random forest for classification on the Titanic and Spam datasets. The decision tree calculates a split that maximizes information gain, and builds a tree structure maintaining class probabilities. Traversal stops when a class reaches a probability of 1.0, or we reach a specified maximum depth. The random forest implements the bagging ensemble method, training individual trees on random subsets of the data, then outputting the mode of all predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import genfromtxt\n",
    "import scipy.io\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "%matplotlib inline\n",
    "\n",
    "class Node:\n",
    "    \"\"\"\n",
    "    A single node in the decision tree:\n",
    "    \n",
    "    left: pointer to left subtree\n",
    "    right: pointer to right subtree\n",
    "    split_rule: A pair containing a feature and threshold to split on (f, t).\n",
    "    depth: The current depth of the node in the tree\n",
    "    probs: Probability of each class label at this node\n",
    "    \"\"\"\n",
    "    def __init__(self, left, right, rule, depth, probs = None):\n",
    "        self.split_rule = rule\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.depth = depth\n",
    "        self.probs = probs\n",
    "    \n",
    "class DecisionTree:\n",
    "    \n",
    "    def __init__(self, features, classes):\n",
    "        self.classes = classes\n",
    "        self.class_indices = list(range(len(classes)))\n",
    "        self.features = features\n",
    "        \n",
    "    def entropy(self, y):\n",
    "        \"\"\"\n",
    "        Calculates the entropy given all the labels\n",
    "        \"\"\"\n",
    "        probs = np.array([np.mean([int(y_i == label) for y_i in y]) for label in self.class_indices])\n",
    "        return stats.entropy(probs)\n",
    "\n",
    "    def information_gain(self, X, y, idx, thresh):\n",
    "        \"\"\"\n",
    "        Calculates information gain given a vector of features and a split threshold\n",
    "        \"\"\"\n",
    "        left, right = self.split(X, y, idx, thresh)\n",
    "        left_H = self.entropy(y[left]) if list(left) else 0\n",
    "        right_H = self.entropy(y[right]) if list(right) else 0\n",
    "        H_after = (len(left) * left_H + len(right) * right_H) / len(y)\n",
    "        return self.entropy(y) - H_after\n",
    "\n",
    "    def split(self, X, y, idx, thresh):\n",
    "        \"\"\"\n",
    "        Returns a split of the dataset given an index of the feature and\n",
    "        a threshold for it\n",
    "        \n",
    "        \"\"\"\n",
    "        left, right = [], []\n",
    "        f = self.features[idx]\n",
    "        for i in range(len(X)):\n",
    "            point = X[i]\n",
    "            comparison = lambda x,y : (x == y if f in [\"pclass\", \"sex\", \"embarked\"] else x < y)\n",
    "            if comparison(point[idx], thresh):\n",
    "                left.append(i)\n",
    "            else:\n",
    "                right.append(i)\n",
    "        return np.array(left), np.array(right)\n",
    "        \n",
    "    def segmenter(self, X, y):\n",
    "        \"\"\"\n",
    "        Compute entropy gain for all single-dimension splits,\n",
    "        return the feature and the threshold for the split that\n",
    "        has maximum gain\n",
    "        \"\"\"\n",
    "        best_gain = -float('inf')\n",
    "        best_pair = None\n",
    "        for i in range(len(self.features)):\n",
    "            thresholds = list(set(X[:,i]))\n",
    "            for threshold in thresholds:\n",
    "                curr_gain = self.information_gain(X, y, i, threshold)\n",
    "                if curr_gain > best_gain:\n",
    "                    best_pair = (i, threshold)\n",
    "                    best_gain = curr_gain\n",
    "        return best_pair\n",
    "             \n",
    "    def fit(self, X, y, max_depth):\n",
    "        \"\"\"\n",
    "        Fit the model to a training set.\n",
    "        \"\"\"\n",
    "        self.root = self.grow_tree(X, y, 0, max_depth)\n",
    "        \n",
    "    def grow_tree(self, X, y, curr_depth, max_depth):\n",
    "        probs = np.array([np.mean([int(y_i == c) for y_i in y]) for c in self.class_indices])\n",
    "        feature, threshold = self.segmenter(X, y)\n",
    "        left, right = self.split(X, y, feature, threshold)\n",
    "        X_left = None if not list(left) else X[left]\n",
    "        y_left = None if not list(left) else y[left]\n",
    "        X_right = None if not list(right) else X[right]\n",
    "        y_right = None if not list(right) else y[right]\n",
    "        if 1.0 in probs or curr_depth == max_depth:\n",
    "            return Node(None, None, None, curr_depth, probs)\n",
    "        if X_left is not None:\n",
    "            left_node = self.grow_tree(X_left, y_left, curr_depth + 1, max_depth)\n",
    "        else:\n",
    "            left_node = Node(None, None, None, curr_depth + 1, probs)\n",
    "        if X_right is not None:\n",
    "            right_node = self.grow_tree(X_right, y_right, curr_depth + 1, max_depth)\n",
    "        else:\n",
    "            right_node = Node(None, None, None, curr_depth + 1, probs)\n",
    "        return Node(left_node, right_node, (feature, threshold), curr_depth)\n",
    "   \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the labels for input data \n",
    "        \"\"\"\n",
    "        y = []\n",
    "        for point in X:\n",
    "            node = self.root\n",
    "            while node is not None and node.probs is None:\n",
    "                feature, threshold = node.split_rule\n",
    "                comparison = lambda x,y : (x == y if self.features[feature] in [\"pclass\", \"sex\", \"embarked\"] else x < y)\n",
    "                node = node.left if comparison(point[feature], threshold) else node.right\n",
    "            y.append(np.argmax(node.probs))\n",
    "        return np.array(y)\n",
    "                    \n",
    "    \"\"\"\n",
    "    Visualization method for the tree\n",
    "    \"\"\"    \n",
    "    def generateString(self, node):\n",
    "        if not node:\n",
    "            return \"\"\n",
    "        if node.probs is not None:\n",
    "            output = \"(\"\n",
    "            for i in range(len(node.probs)):\n",
    "                output += f\"{self.classes[i]} : {node.probs[i]}, \"\n",
    "            output = output[:-2] + \")\\n\"\n",
    "            return \"\\t\" * node.depth + output\n",
    "        fidx, thresh = node.split_rule\n",
    "        return \"\\t\" * node.depth + f\"{self.features[fidx]}, {thresh}\\n\" + \"\\t\" * node.left.depth + self.generateString(node.left) + \"\\t\" * node.right.depth + self.generateString(node.right)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        \n",
    "        return self.generateString(self.root)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    \n",
    "    def __init__(self, features, classes, num_trees):\n",
    "        \"\"\"\n",
    "        Initialization of a random forest\n",
    "        \"\"\"\n",
    "        self.trees = np.array([DecisionTree(features, classes) for _ in range(num_trees)])\n",
    "    def fit(self, X, y, max_depth):\n",
    "        \"\"\"\n",
    "        Fit the model to a training set\n",
    "        \"\"\"\n",
    "        for tree in self.trees:\n",
    "            X_t, y_t = [], []\n",
    "            for _ in range(len(y)):\n",
    "                idx = np.random.randint(len(y))\n",
    "                X_t.append(X[idx])\n",
    "                y_t.append(y[idx])\n",
    "            \n",
    "            tree.fit(np.array(X_t), np.array(y_t), max_depth)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the labels for input data \n",
    "        \"\"\"\n",
    "        predictions = np.array([tree.predict(X) for tree in self.trees])\n",
    "        final_predictions = np.array([stats.mode(predictions[i, :])[0][0] for i in range(len(predictions))])\n",
    "        return final_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perfomance Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will preprocess the data to encode categorical values and fill in missing values. Then, we will train our models and measure their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nprasad/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:34: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "/Users/nprasad/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:35: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n"
     ]
    }
   ],
   "source": [
    "# Check if s is a numerical value\n",
    "def is_numeric(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except (ValueError, TypeError):\n",
    "        return False\n",
    "# Preprocess the data by converting from strings to floats, and encoding categorical data with the LabelEncoder      \n",
    "def process_data(features, dataset):\n",
    "    for i in range(len(features)):\n",
    "            column = dataset[:,i]\n",
    "            for j in range(len(column)):\n",
    "                if column[j] == '':\n",
    "                    values = np.array([x for x in column if x != ''])\n",
    "                    if all(list(map(is_numeric, values))):\n",
    "                        values = values.astype(np.float64)\n",
    "                        column[j] = np.mean(values)\n",
    "            dataset[:,i] = column\n",
    "            # Label encoding for categorical features\n",
    "            le = LabelEncoder()\n",
    "            if not is_numeric(dataset[0,i]):\n",
    "                le.fit(dataset[:,i])\n",
    "                dataset[:,i] = le.transform(dataset[:,i])\n",
    "    \n",
    "    return dataset.astype(np.float64)\n",
    "\n",
    "\"\"\"\n",
    "Read in the datasets from given files and run preprocessing.\n",
    "\"\"\"\n",
    "def generate_data(dataset):\n",
    "    # The titanic dataset requires preprocessing to convert categorical data and fill in missing values\n",
    "    if dataset == \"titanic\":\n",
    "    # Load titanic data       \n",
    "        data = genfromtxt('titanic_training.csv', delimiter=',', dtype=None)\n",
    "        test_data = genfromtxt('titanic_testing_data.csv', delimiter=',', dtype=None)\n",
    "        y = data[1:, 0]\n",
    "        class_names = [\"Died\", \"Survived\"]\n",
    "        features = data[0].astype(np.str)\n",
    "        data = process_data(features, data[1:].astype(np.str))\n",
    "        test_features = test_data[0].astype(np.str)\n",
    "        test_data = process_data(test_features, test_data[1:].astype(np.str))\n",
    "        y = y.astype(np.str)\n",
    "        empty_indices = [i for i in range(len(y)) if y[i] == '']\n",
    "        # Remove the indices with empty data\n",
    "        for i in empty_indices:\n",
    "            data = np.delete(data,i,0)\n",
    "            y = np.delete(y,i)\n",
    "        y = y.astype(np.int)\n",
    "    # The spam dataset does not require the above preprocessing: simply load the data    \n",
    "    elif dataset == \"spam\":\n",
    "        features = [\n",
    "        \"pain\", \"private\", \"bank\", \"money\", \"drug\", \"spam\", \"prescription\",\n",
    "        \"creative\", \"height\", \"featured\", \"differ\", \"width\", \"other\",\n",
    "        \"energy\", \"business\", \"message\", \"volumes\", \"revision\", \"path\",\n",
    "        \"meter\", \"memo\", \"planning\", \"pleased\", \"record\", \"out\",\n",
    "        \"semicolon\", \"dollar\", \"sharp\", \"exclamation\", \"parenthesis\",\n",
    "        \"square_bracket\", \"ampersand\"\n",
    "        ]\n",
    "        assert len(features) == 32\n",
    "\n",
    "    # Load spam data\n",
    "        data = scipy.io.loadmat('spam_data.mat')\n",
    "        X = data['training_data']\n",
    "        y = np.squeeze(data['training_labels'])\n",
    "        test_data = data['test_data']\n",
    "        class_names = [\"Ham\", \"Spam\"]\n",
    "        data = X\n",
    "    return data, y, test_data, features, class_names\n",
    "         \n",
    "    \n",
    "\n",
    "titanic_X, titanic_y, titanic_test, titanic_features, titanic_classes = generate_data(\"titanic\")\n",
    "spam_X, spam_y, spam_test, spam_features, spam_classes = generate_data(\"spam\")\n",
    "titanic_X = np.delete(titanic_X,0,1)\n",
    "titanic_features = titanic_features[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we measure the performance of both models through training and validation accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and validate both models, outputting training and validation accuracies\n",
    "X_train_t, X_val_t, y_train_t, y_val_t = tts(titanic_X, titanic_y, test_size=0.8, random_state=42)\n",
    "X_train_s, X_val_s, y_train_s, y_val_s = tts(spam_X, spam_y, test_size=0.8, random_state=42)\n",
    "titanic_tree = DecisionTree(titanic_features, titanic_classes)\n",
    "titanic_forest = RandomForest(titanic_features, titanic_classes, 5)\n",
    "spam_tree = DecisionTree(spam_features, spam_classes)\n",
    "spam_forest = RandomForest(spam_features, spam_classes, 5)\n",
    "titanic_tree.fit(X_train_t, y_train_t, 10)\n",
    "titanic_forest.fit(X_train_t, y_train_t, 10)\n",
    "spam_tree.fit(X_train_s, y_train_s, 10)\n",
    "spam_forest.fit(X_train_s, y_train_t, 10)\n",
    "titanic_tree_pred_tr = titanic_tree.predict(X_train_t)\n",
    "titanic_tree_pred_va = titanic_tree.predict(X_val_t)\n",
    "spam_tree_pred_tr = spam_tree.predict(X_train_s)\n",
    "spam_tree_pred_va = spam_tree.predict(X_val_s)\n",
    "titanic_forest_pred_tr = titanic_forest.predict(X_train_t)\n",
    "titanic_forest_pred_va = titanic_forest.predict(X_val_t)\n",
    "spam_tree_forest_tr = spam_forest.predict(X_train_s)\n",
    "spam_tree_forest_va = spam_forest.predict(X_val_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy for Titanic with Decision Tree: 0.9547738693467337\n",
      "Validation accuracy for Titanic with Decision Tree: 0.74\n",
      "Training accuracy for Titanic with Random Forest: 0.8\n",
      "Validation accuracy for Titanic with Random Forest: 0.8\n",
      "Training accuracy for Spam with Decision Tree: 0.8558994197292069\n",
      "Validation accuracy for Spam with Decision Tree: 0.7982116964717255\n",
      "Training accuracy for Spam with Random Forest: 0.8\n",
      "Validation accuracy for Spam with Random Forest: 1.0\n"
     ]
    }
   ],
   "source": [
    "def calc_acc(pred, actual):\n",
    "    return np.mean([int(pred[i] == actual[i]) for i in range(len(pred))])\n",
    "\n",
    "training_acc_titanic_tree = calc_acc(titanic_tree_pred_tr, y_train_t)\n",
    "validation_acc_titanic_tree = calc_acc(titanic_tree_pred_va, y_val_t)\n",
    "training_acc_titanic_forest = calc_acc(titanic_forest_pred_tr, y_train_t)\n",
    "validation_acc_titanic_forest = calc_acc(titanic_forest_pred_va, y_val_t)\n",
    "training_acc_spam_tree = calc_acc(spam_tree_pred_tr, y_train_s)\n",
    "validation_acc_spam_tree = calc_acc(spam_tree_pred_va, y_val_s)\n",
    "training_acc_spam_forest = calc_acc(spam_tree_forest_tr, y_train_s)\n",
    "validation_acc_spam_forest = calc_acc(spam_tree_forest_va, y_val_s)\n",
    "print(f\"Training accuracy for Titanic with Decision Tree: {training_acc_titanic_tree}\")\n",
    "print(f\"Validation accuracy for Titanic with Decision Tree: {validation_acc_titanic_tree}\")\n",
    "print(f\"Training accuracy for Titanic with Random Forest: {training_acc_titanic_forest}\")\n",
    "print(f\"Validation accuracy for Titanic with Random Forest: {validation_acc_titanic_forest}\")\n",
    "print(f\"Training accuracy for Spam with Decision Tree: {training_acc_spam_tree}\")\n",
    "print(f\"Validation accuracy for Spam with Decision Tree: {validation_acc_spam_tree}\")\n",
    "print(f\"Training accuracy for Spam with Random Forest: {training_acc_spam_forest}\")\n",
    "print(f\"Validation accuracy for Spam with Random Forest: {validation_acc_spam_forest}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we plot the validation error as a function of tree depth for both the decision tree and random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation Accuracy on Spam Dataset')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd3wUdfrA8c+TTSMhhJIAQigB6V0DiFhAUUEp6qnYOOvZ29l+WM6CnoeKXc6OhUMR8FBORZqgIioECF06SEBJqBJa2vP7YyZxEwNsIMlsNs/79dpXpnxn5tnZzbMzz85+R1QVY4wxoSvM6wCMMcaUL0v0xhgT4izRG2NMiLNEb4wxIc4SvTHGhDhL9MYYE+Is0VcSItJURFREwt3xySJyVSBtj2JbD4rI28cSrzEmeFiiryAiMkVEhpUwfZCI/FbapKyq/VT1/TKIq5eIpBdb91Oqev2xrvsI21QRub+8thFKRKSdiEwVkZ0isktE5ovIuUEQ12MikiMie9zHKhF5VUSOK8U6ZolIub3XKno7wcoSfcV5DxgiIlJs+hBgjKrmVnxInrkK2OH+rVBHe5bjsf8B04B6QF3gDuB3TyP6w8eqGgfUBi4A6gPzS5PsTQVQVXtUwAOoBuwGTvObVgs4AHRyx88DFuL8E28CHvNr2xRQINwdnwVc7w77gBHANmAdcGuxttcAK4A97vwb3emxwH4gH8hyHw2Ax4D/+G17ILAM2OVut43fvA3AvcBi9/l9DEQfZj/EuHFcCmQDKcXmnwLMcbe1Cbjab/89B2x0tzPbndYLSC+2jg1AH3f4MWAC8B93v14PdAN+cLfxK/AqEOm3fDucxLoD2Ao8iJPA9gF1/NqdCGQCESU8zyjgRWCL+3gRiHLn9QLSgXuADDeGaw6xvxLc17LmIeYXrOtB9/XfAFzhNz+Q99Q17rydwE1AV/f13AW8epjXssj7xO+9uAgY4fce/9zdTzvd4SR33j+BPJz/gayCbQEvufH8DswHTvVbfzcg1Z23FXjeb95Jfu+dRUCvw22nKj08D6AqPYC3gLf9xm8E0vzGewEdcM60Orpv5PPdeQX/lCUl+puAn4FGOEdWM4u1PQ9oDghwOk7COsFvm8UTZeE/MNAS2AucBUQA9wNrcBOjm1jm4nxA1Mb5QLnpMPtgCE5i8+Ecqb7sN68xzofAZe626gCd3Xkj3efc0F32ZJxkWlL8Gyia6HOA8939Wg0nQZ8EhLv7dQVwl9s+zo3vHiDaHe/uzvsSuNlvOy8ArxzieQ4DfsQ5Ak/ESUBP+O3zXLdNBHCu+5rUKmE9AqzGSZDnA/WKzS9Y1/Pu/jjdfb1aleI99br7XM/GSYafunE3xPkgOv0Qz7HwfVLCc//JHa4D/AXnAz4OGA986td2Fu772G/ale5y4e7r8BvuwQPOB/QQd7g6cJI73BDY7u7LMJz363Yg8VDbqUoPzwOoSg+co9XdQDV3/Hvg74dp/yLwgjtc8E9ZUqL/Gr/k6v7DFrYtYb2fAne6w704fKL/BzDOb14YsJk/jpY2AFf6zX8GeP0wz2k68KI7fBl+R8TAA8DEEpYJwznz6FTCvJLi30DRRP/tEV6Xuwq268a08BDtBgPfu8M+NwF1O0TbtcC5fuPnABv8Yt7v//rgJNSTDrGuJJyzjrU4Z1/fAi381pULxPq1Hwf8oxTvqYZ+87cDg/3GP8H9ECxhXYXvk2LTbwJWH2KZzsBOv/HC9/FhXp+d/HHW+y3wOJBQrM3/AaOLTZsCXBXodkL5YTX6CqSqs3ES2yARaYZzivxhwXwR6S4iM0UkU0R24/zDJASw6gY4p7oFNvrPFJF+IvKjiOwQkV04Rz2BrLdg3YXrU9V8d1sN/dr85je8D+dI609EpBHQGxjjTvoM50jyPHe8EU4yKy7BbVfSvED47xtEpKWIfO5+Cf478BR/7I9DxVAQb1v3tTsL2K2qcw/Rtsh+c4cb+I1v16Lfyxxyv6lquqrepqrNgSY4R+wf+DXZqap7S9pWgO+prX7D+0sYLzGuw2iIU/ZCRGJE5A0R2eju62+BmiLiO9TCInKPiKwQkd3u+zXeL+brcM4yfxaReSLS353eBLjY/bJ6l7vcKYB9V4B9GeuFD4C/4pQwpqqq/z/Vh8AkoJGqxuOcUhf/8rYkv+IkqAKNCwZEJArnqGwEzml/TZwSRMF69Qjr3oLzT1SwPnG3tTmAuIobgvOe+5+I/IbzfUE0zv4AJyE3L2G5bTglhZLm7cUpCxTE58Mplfgr/hxfwyl1tVDVGjj17YL9cagYUNUDOEfLV7jPZXRJ7VxF9hvOa7LlMO0DoqqbcMpY7f0m1xKR2ENs62jfU0dFRMKAAcB37qR7gFY45a8awGkFTd2/Wmz5U3GOzi/BKWXVxDkLFgBVXa2ql+GUlp4GJrjPfRPOEX1Nv0esqg4vaTtVjSX6ivcB0Af4G1D88sg4YIeqHhCRbsDlAa5zHHCHiCSJSC1gqN+8SJzabSaQKyL9cEo7BbYCdUQk/jDrPk9EzhSRCJx/3IM4NefS+ivOaXdnv8df3PXXwTnS7yMil4hIuIjUEZHO7lnEKOB5EWkgIj4R6eF+iK0CokXkPDe+h93nezhxOF/mZYlIa+Bmv3mfA/VF5C4RiRKROBHp7jf/A+BqnC+o/3OYbXwEPCwiiSKSADxyhPYlEpFaIvK4iBwvImHuuq7Fqf/7e1xEIt1E2R+nFl7wXI/mPVXaOCNEpA3O866P851Bwfb3A7tEpDbwaLFFtwLN/MbjcEpRmUC4iDwC1PDbzpUikui+J3a5k/Nw9u0AETnHfX9Eu5fxJh1iO1WKJfoKpqobcJJkLM6Rlr9bgGEisgcnMYwLcLVv4dQjFwELgP/6bW8PzuV443BqnZf7b1dVf8b551znnvL6lxdQ1ZU4X469gnNkPQAYoKrZAcYGgIichFMTHqmqv/k9JuF8uXuZqv6CU1a6B+fUPw3o5K7iXmAJMM+d9zQQpqq7cfbb2zhnGXtxrkI5nHvd/bAHZ9997Pd89+CUZQbglKRW45SbCuZ/j1MnX+C+lofyJM7VIYvduBe400orG2e/Tcf5cFqK80F7tV+b33Be2y04H5Y3ua8rHP17KlCDRSQLJ+lOwqnxn6iqBWcUL+J8Ab4N58Ppq2LLvwRc5P5G4GWc9/FknA/wjThncv6lt77AMnebLwGXquoB90xnEM7ZWaa7zH38keOKb6dKEfeLCmNMgETka+BDVfX818Mi0gvnC9GkI7U1VVdl/PGIMZ4Rka7ACThHj8ZUCla6MSZAIvI+TgnlLrfEY0ylYKUbY4wJcXZEb4wxIS7oavQJCQnatGlTr8MwxphKZf78+dtUtfhvSIAgTPRNmzYlNTXV6zCMMaZSEZGNh5pnpRtjjAlxluiNMSbEWaI3xpgQZ4neGGNCnCV6Y4wJcQElehHpKyIrRWSNiAwtYf7dIrJcRBaLyAwR8e/WNk9E0txH8U68jDHGlLMjXl7p9u89EqdHv3RgnohMUtXlfs0W4tz7c5+I3Ixzl6HB7rz9qtq5jOM2xhgToECuo+8GrFHVdQAiMhanQ6fCRK+qM/3a/4jTrW3FmzwUflviyaaNMeaY1e8A/YYfuV0pBVK6aUjR/qDTKXobueKuw+lPukC0iKS6t7I7v6QFROQGt01qZmZmACEZY4wJVCBH9CXddqzEntBE5EogBedO9AUaq+oW9z6bX4vIElUtck9OVX0TeBMgJSXl6HtZK4dPQmOMqewCOaJPp+j9SJMo4d6XItIHeAgYqKoHC6YX3GnGLf3MArocQ7zGGGNKKZBEPw9oISLJIhIJXEqxW+CJSBfgDZwkn+E3vZZ7X0/ce132xK+2b4wxpvwdsXSjqrkichvOvRx9wChVXSYiw4BU956fzwLVgfEiAvCLqg4E2gBviEg+zofK8GJX6xhjjClnQXfjkZSUFLXeK40xpnREZL6qppQ0z34Za4wxIc4SvTHGhDhL9MYYE+Is0RtjTIizRG+MMSHOEr0xxoQ4S/TGGBPiLNEbY0yIs0RvjDEhzhK9McaEOEv0xhgT4izRG2NMiLNEb4wxIc4SvTHGhDhL9MYYE+Is0RtjTIizRG+MMSHOEr0xxoQ4S/TGGBPiLNEbY0yIs0RvjDEhzhK9McaEOEv0xhgT4izRG2NMiLNEb4wxIc4SvTHGhLiAEr2I9BWRlSKyRkSGljD/bhFZLiKLRWSGiDQpNr+GiGwWkVfLKnBjjDGBOWKiFxEfMBLoB7QFLhORtsWaLQRSVLUjMAF4ptj8J4Bvjj1cY4wxpRXIEX03YI2qrlPVbGAsMMi/garOVNV97uiPQFLBPBE5EagHTC2bkI0xxpRGIIm+IbDJbzzdnXYo1wGTAUQkDHgOuO9wGxCRG0QkVURSMzMzAwjJGGNMoAJJ9FLCNC2xociVQArwrDvpFuBLVd1UUvvClam+qaopqpqSmJgYQEjGGGMCFR5Am3Sgkd94ErCleCMR6QM8BJyuqgfdyT2AU0XkFqA6ECkiWar6py90jTHGlI9AEv08oIWIJAObgUuBy/0biEgX4A2gr6pmFExX1Sv82lyN84WtJXljjKlARyzdqGoucBswBVgBjFPVZSIyTEQGus2exTliHy8iaSIyqdwiNsYYUyqiWmK53TMpKSmamprqdRjGGFOpiMh8VU0paZ79MtYYY0JcyCT67VkHuWXMfJZt2e11KMYYE1RCJtGHiTBvw07uHb+Y7Nx8r8MxxpigETKJvlZsJE9d0IEVv/7OqzPXeB2OMcYEjZBJ9ABnta3HhSc0ZOTMNSzdbCUcY4yBEEv0AI8OaEdC9UjuHpfGwdw8r8MxxhjPhVyij68WwfC/dGTV1ixemr7a63CMMcZzIZfoAXq3qsvglEa8/s1a0jbt8jocY4zxVEgmeoCH+rehfo1o7hmXxoEcK+EYY6qukE30NaIjePqijqzN3MsL01Z5HY4xxngmZBM9wKktErm8e2Pe/G4d8zfu8DocY4zxREgneoAHz21Dg/hq3Dt+MfuzrYRjjKl6Qj7RV48K59mLOrJ+215GTF3pdTjGGFPhQj7RA5x8fAJ/7dGEUd+vZ+56K+EYY6qWKpHoAf6vb2sa1YrhvgmL2Jed63U4xhhTYapMoo91Szgbt+/jma+shGOMqTqqTKIH6N6sDtf0bMp7czbww9rtXodjjDEVokoleoD7z2lNckIs901YRNZBK+EYY0JflUv01SJ9jLi4I5t37edfX67wOhxjjCl3VS7RA5zYpDZ/O7UZY376he9WZ3odjjHGlKsqmegB7j6rJc0TY/m/CYvZcyDH63CMMabcVNlEHx3hY8TFnfjt9wP88wsr4RhjQleVTfQAXRrX4sbTmzN23iZmrczwOhxjjCkXVTrRA9zVpwUt61Vn6CdL2L3fSjjGmNBT5RN9VLhTwsnMOsgTny/3OhxjjClzASV6EekrIitFZI2IDC1h/t0islxEFovIDBFp4k5vIiLzRSRNRJaJyE1l/QTKQsekmtzSqzkT5qczY8VWr8MxxpgydcRELyI+YCTQD2gLXCYibYs1WwikqGpHYALwjDv9V+BkVe0MdAeGikiDsgq+LN1+Rgta14/jgf8uYde+bK/DMcaYMhPIEX03YI2qrlPVbGAsMMi/garOVNV97uiPQJI7PVtVD7rTowLcniciw8MYcXEnduzN5vH/WQnHGBM6Akm8DYFNfuPp7rRDuQ6YXDAiIo1EZLG7jqdVdUvxBUTkBhFJFZHUzEzvfsDUvmE8t51xPBMXbmbKst88i8MYY8pSIIleSpimJTYUuRJIAZ4tbKi6yS3pHA9cJSL1/rQy1TdVNUVVUxITEwOLvJzc2vt42jWowUMTl7Bjr5VwjDGVXyCJPh1o5DeeBJR0VN4HeAgY6FeuKeQeyS8DTj26UCtGhC+M5y7pxO79OTzy2VKvwzHGmGMWSKKfB7QQkWQRiQQuBSb5NxCRLsAbOEk+w296kohUc4drAT2BoO8MvnX9GtzVpyWfL/6VLxb/6nU4xhhzTI6Y6FU1F7gNmAKsAMap6jIRGSYiA91mzwLVgfHupZQFHwRtgJ9EZBHwDTBCVZeU+bMoBzee1oyOSfH847OlbMv60wmKMcZUGqJaYrndMykpKZqamup1GACs3rqH816ezZlt6vLvK05ApKSvK4wxxnsiMl9VU0qaF7SXOwaDFvXiuPvslkxe+hv/sxKOMaaSskR/BH87tRldGtfkkc+WkrHngNfhGGNMqVmiPwJfmDDi4k7sz87joYlLCbZSlzHGHIkl+gA0T6zOfee0YtryrXyattnrcIwxplQs0Qfomp7JpDSpxaOfLWPr71bCMcZUHpboA+QLE569uBPZefkM/WSxlXCMMZWGJfpSSE6I5f/6tmbmykzGz0/3OhxjjAmIJfpSuqpHU7on1+aJ/y1ny679XodjjDFHZIm+lMLChGcv6kSeKv9nJRxjTCVgif4oNK4TwwPntuG71dsYO2/TkRcwxhgPWaI/Sld0a0zP4+vw5OfLSd+578gLGGOMRyzRH6WwMOHpv3QE4P4Ji8nPtxKOMSY4WaI/Bkm1Yni4f1vmrN3OmLm/eB2OMcaUyBL9Mbq0ayNObZHAv75cwS/brYRjjAk+luiPkYhTwvGJcN+ERVbCMcYEHUv0ZaBBzWr8Y0Bbflq/gw9+2OB1OMYYU4Ql+jJy8YlJ9G6VyPCvfmbDtr1eh2OMMYUs0ZcREeFfF3Yk0hfGveMXkWclHGNMkLBEX4bqx0fz2MB2pG7cybvfr/c6HGOMASzRl7kLujSkT5t6PDtlJWsysrwOxxhjLNGXNRHhqQvbUy3SZyUcY0xQsERfDurGRTNsUHvSNu3ire/WeR2OMaaKs0RfTgZ0PI5+7evz/NRVrN66x+twjDFVmCX6ciIiPHF+e6pHh3PP+EXk5uV7HZIxpoqyRF+OEqpH8cSg9ixO380rX6/xOhxjTBUVUKIXkb4islJE1ojI0BLm3y0iy0VksYjMEJEm7vTOIvKDiCxz5w0u6ycQ7M7reBwXntCQl79ezZw127wOxxhTBR0x0YuIDxgJ9APaApeJSNtizRYCKaraEZgAPONO3wf8VVXbAX2BF0WkZlkFX1k8eX57midW546xaWTsOeB1OMaYKiaQI/puwBpVXaeq2cBYYJB/A1WdqaoFXTf+CCS501ep6mp3eAuQASSWVfCVRUxkOCMvP4Gsgzn8/eM0u+TSGFOhAkn0DQH/++Wlu9MO5TpgcvGJItINiATWlibAUNGqfhzDBrXn+zXbedXq9caYChRIopcSppV4SCoiVwIpwLPFph8HjAauUdU/XX4iIjeISKqIpGZmZgYQUuV08YlJXNilIS/OWGX1emNMhQkk0acDjfzGk4AtxRuJSB/gIWCgqh70m14D+AJ4WFV/LGkDqvqmqqaoakpiYuhWdgouuWyWEGv1emNMhQkk0c8DWohIsohEApcCk/wbiEgX4A2cJJ/hNz0SmAh8oKrjyy7syis2Kpx/X3Gi1euNMRXmiIleVXOB24ApwApgnKouE5FhIjLQbfYsUB0YLyJpIlLwQXAJcBpwtTs9TUQ6l/3TqFxa1Y9j2ECnXj9yptXrjTHlS1SD64gyJSVFU1NTvQ6j3Kkq94xbxKdpm/nP9d05uXmC1yEZYyoxEZmvqiklzbNfxnqkoF6fnBDLnWPTyNxz8MgLGWPMUbBE76HYqHBGXnECv++3er0xpvxYovdY6/o1GDaoHbPXbLN6vTGmXFiiDwKXpDTigi4NeXH6KuastevrjTFlyxJ9EBARnjy/PU2tXm+MKQeW6IOEc3291euNMWXPEn0Q8a/X/9vq9caYMmKJPshcktKI8zs34IXpq/hh7XavwzHGhABL9EFGRPjnBR1omhDLHWMXWr3eGHPMLNEHodgop/96q9cbY8qCJfog1ea4Gjw+0Or1xphjZ4k+iA3u+ke9/sd1Vq83xhwdS/RBrEi9/qOFbMuyer0xpvQs0Qe5gnr9brden2/1emNMKVmirwTaHFeDxwa247vV2/j3LKvXG2NKxxJ9JXFp10YM6tyA56dZvd4YUzqW6CuJwnp9HavXG2NKxxJ9JVLd7b/e6vXGmNKwRF/J+NfrX/tmrdfhGGMqAUv0ldClXRsxsFMDnpu6kp+sXm+MOQJL9JWQiPDUhR1oUsfpD8fq9caYw7FEX0lVd6+v37nP6vXGmMOzRF+JtW1Qg8cGWL3eGHN4lugrucu6/VGvn7t+h9fhGGOCkCX6Ss6/Xn/7RwvYbvV6Y0wxluhDQJF6/bhFVq83xhQRUKIXkb4islJE1ojI0BLm3y0iy0VksYjMEJEmfvO+EpFdIvJ5WQZuimrboAaPDmjLt6syrV5vjCniiIleRHzASKAf0Ba4TETaFmu2EEhR1Y7ABOAZv3nPAkPKJlxzOJd3a8wAq9cbY4oJ5Ii+G7BGVdepajYwFhjk30BVZ6rqPnf0RyDJb94MYE8ZxWsOQ0R46oL2Vq83xhQRSKJvCGzyG093px3KdcDk0gQhIjeISKqIpGZmZpZmUVNMXHQEr17ehZ37crjb6vXGGAJL9FLCtBKzh4hcCaTglGsCpqpvqmqKqqYkJiaWZlFTgnYN4nl0QFu+WZXJ699avd6Yqi6QRJ8ONPIbTwK2FG8kIn2Ah4CBqmo1A49d3q0x/Tsex3NTV1m93pgqLpBEPw9oISLJIhIJXApM8m8gIl2AN3CSfEbZh2lKS0T414UdaFSrGnd8tNDq9cZUYUdM9KqaC9wGTAFWAONUdZmIDBORgW6zZ4HqwHgRSRORwg8CEfkOGA+cKSLpInJOmT8LUyKnXn8CO/ZlW73emCpMVIPrnz8lJUVTU1O9DiOk/OfHjTz86VLu79uKW3od73U4xphyICLzVTWlpHn2y9gq4Iruf9Tr522wer0xVY0l+irAv15/+4cL2bE32+uQjDEVyBJ9FVFYr9+bzd3jrP96Y6oSS/RVSPuG8fxjQFtmrczkjW/XeR2OMaaCWKKvYq7s3pjzOh7HiKkrrV5vTBVhib6KERGGX9iBJLdev3nXfq9DMsaUM0v0VVBcdAQj3evrT3n6ay749/eMnLmGVVv3EGyX2xpjjp1dR1+FrcvM4ovFvzJtxVYWp+8GoEmdGPq0qcdZbeuR0qQW4T47FjCmMjjcdfSW6A0Av+0+wPQVW5m+Yitz1mwnOy+f+GoRnNG6Lme1rcdpLROpHhXudZjGmEOwRG9KJetgLt+tymTaiq18/XMGu/blEOkLo0fzOvRpW4+z2tSjfny012EaY/xYojdHLTcvn/kbdzJ9xVamLd/Khu3O/WU6NIwvLPG0OS4OkZJ6szbGVBRL9KZMqCprM7OYunwr05dvZeGmXahCw5rVOKttPfq0qUe35NpEhltd35iKZonelIvMPQf5+uetTFuewew1mRzIyScuOpxererSp01derWqS3y1CK/DNKZKsERvyt3+7Dxmr9nG9OVbmfHzVrZlZRMeJnRvVps+bZyj/Ua1Y7wO05iQZYneVKi8fCVt0y6mLXeu4lmTkQVA6/pxnN22Hn3a1qNDw3ir6xtThizRG0+t37aX6cudL3NTN+4gX6FejSjnSL9tPU5uXoeocJ/XYRpTqVmiN0Fjx95sZv6cwbTlW/l2dSb7svOIjfRxWstEzmpbj96t6lIrNtLrMI2pdCzRm6B0ICePH9Ztd0o8y7eSsecgYQIpTWsz5KQm9O94nJV3jAmQJXoT9PLzlSWbdzN9xVa+WPIr6zL3cmKTWvyjf1s6N6rpdXjGBD1L9KZSyctXJszfxLNTVrEt6yAXdmnIfX1bcVx8Na9DMyZo2T1jTaXiCxMGd23MrPt6cUuv5ny+5Fd6j5jFi9NXsT87z+vwjKl0LNGboFU9Kpz7+7Zmxt2nc2aberw4fTVnPDeLiQvT7VaIxpSCJXoT9BrVjmHk5Scw/qYeJMZF8fePF3HBa3OYv9HukGVMICzRm0qja9PafHpLT567uBO/7d7PX177gds/Wkj6zn1eh2ZMULNEbyqVsDDhLycmMfPeXtxxZgumLvuNM5/7hhFTVrL3YK7X4RkTlAJK9CLSV0RWisgaERlawvy7RWS5iCwWkRki0sRv3lUistp9XFWWwZuqKyYynLvPasnX9/aib/v6vDpzDb1GzGJc6iar3xtTzBEvrxQRH7AKOAtIB+YBl6nqcr82vYGfVHWfiNwM9FLVwSJSG0gFUgAF5gMnqurOQ22vpMsrc3JySE9P58CBA0fzHI2HoqOjSUpKIiKifHuxXPDLTp74fDkLf9lF+4Y1+Md5benerE65btOYYHK4yysDuTdcN2CNqq5zVzYWGAQUJnpVnenX/kfgSnf4HGCaqu5wl50G9AU+Ks0TSE9PJy4ujqZNm9ovJSsRVWX79u2kp6eTnJxcrts6oXEt/nvzyUxatIWnJ//M4Dd/pF/7+jzQrw2N61ivmaZqC6R00xDY5Dee7k47lOuAyaVZVkRuEJFUEUnNzMz80woPHDhAnTp1LMlXMiJCnTp1KuxMTEQY1LkhM+7pxT1ntWTWykz6PP8N/5q8gj0HciokBmOCUSCJvqTsWmK9R0SuxCnTPFuaZVX1TVVNUdWUxMTEkoOwJF8pefG6VYv0cfuZLZh1Xy8GdGrAG9+so/eIWXw09xfyrH5vqqBAEn060MhvPAnYUryRiPQBHgIGqurB0ixrTHmoVyOa5y7pxKTbepKcEMsD/13CeS9/x5w127wOzZgKFUiinwe0EJFkEYkELgUm+TcQkS7AGzhJPsNv1hTgbBGpJSK1gLPdaZWOz+ejc+fOtGvXjk6dOvH888+Tn59/VOt65JFHmD59+iHnv/7663zwwQdHGyoAS5YsoXPnznTu3JnatWuTnJxM586d6dOnzzGttzLqmFSTcTf24N9XnEDWwVwuf/sn/vZBKuu37fU6NGMqRECdmonIucCLgA8Ypar/FJFhQKqqThKR6UAH4Fd3kV9UdaC77LXAg+70f6rqu4fbVklX3axYsYI2bdqU4mmVverVq5OV5dwpKSMjg8svv5yePXvy+OOPexpXIK6++mr69+/PRRdd9Kd5ubm5hL6zTFEAABQgSURBVIcH8p380QuG16/AgZw8Rn2/npFfryE7L5+rejTl9jNb2L1tTaV3rFfdoKpfAl8Wm/aI3/AhDxNVdRQwKrBQj+zx/y1j+Zbfy2p1ALRtUINHB7QLuH3dunV588036dq1K4899hj5+fkMHTqUWbNmcfDgQW699VZuvPFGAJ555hlGjx5NWFgY/fr1Y/jw4UUS79ChQ5k0aRLh4eGcffbZjBgxgscee4zq1atz7733kpaWxk033cS+ffto3rw5o0aNolatWvTq1Yvu3bszc+ZMdu3axTvvvMOpp54aUPzTp09n+PDhJCQksGzZMpYsWcL777/PyJEjyc7O5uSTT+bVV18lLCyMyZMnM2zYMA4ePEiLFi0YNWoUsbGxR7Wfg0F0hI9beh3PRScm8fzUVbzz/Xo+WZDO3We15LJujQn32W8ITeixd/VRatasGfn5+WRkZPDOO+8QHx/PvHnzmDdvHm+99Rbr169n8uTJfPrpp/z0008sWrSI+++/v8g6duzYwcSJE1m2bBmLFy/m4Ycf/tN2/vrXv/L000+zePFiOnToUOQMIjc3l7lz5/Liiy+W+szixx9/5JlnnmHJkiUsXbqUiRMnMmfOHNLS0sjNzWXs2LFkZGQwfPhwZsyYwYIFC+jYsSMvvfTS0e2wIFM3Lprhf+nI57efQuv6NfjHZ8vo99J3fLPqz1d9GVPZle85ezkozZF3eSsoe02dOpXFixczYcIEAHbv3s3q1auZPn0611xzDTExznXctWvXLrJ8jRo1iI6O5vrrr+e8886jf//+Rebv3r2bXbt2cfrppwNw1VVXcfHFFxfOv/DCCwE48cQT2bBhQ6li79GjB40bNwacI/x58+aRkuKc9e3fv59GjRoRExPD8uXLOfnkkwHIzs7mlFNOKdV2gl27BvF8+LfuTFu+lX9+uYKrRs2lV6tEHj6vDcfXjfM6PGPKRKVL9MFi3bp1+Hw+6tati6ryyiuvcM455xRp89VXXx328sLw8HDmzp3LjBkzGDt2LK+++ipff/11wDFERUUBzhfFubml6+fFv/yiqlx77bU88cQTRdpMnDiRvn37Mnr06FKtu7IREc5uV5/TWyXywZyNvPz1as558TuGnNSEO89sEfL3sFVV8vKV3HwlOy+fnNx8Z9j9m5OXX2TYeajbLp/sPCXXne4/nJOnxFeLoFliLM0Tq1M3Lsouk/aIJfqjkJmZyU033cRtt92GiHDOOefw2muvccYZZxAREcGqVato2LAhZ599NsOGDePyyy8nJiaGHTt2FDmqz8rKYt++fZx77rmcdNJJHH/88UW2Ex8fT61atfjuu+849dRTGT16dOHRfVnq06cPF110EXfeeScJCQls376dvXv3cvLJJ3PnnXeybt06mjVrxt69e9myZQstWrQo8xiCQVS4j7+d1owLT2jIC9NX8cEPG5i4cDN3ntmCIT2aEFHO9fvs3Hz2Z+exLyeXfdl57DuYx77sXPbl5LE/O4+9B3PZn5PnzMvOY392LnuznXnZuflk5+W7SVaLDPsn59yCZJzvJPScPCUnP5+KuNFc9ahwmiXG0iwhlmaJ1d3h6iQnxFIt0lf+AVRhlugDtH//fjp37kxOTg7h4eEMGTKEu+++G4Drr7+eDRs2cMIJJ6CqJCYm8umnn9K3b1/S0tJISUkhMjKSc889l6eeeqpwnXv27GHQoEEcOHAAVeWFF17403bff//9wi9jmzVrxrvvHvaipaPSoUMHHn30Ufr06UN+fj4RERG8/vrrdO3alXfeeYfBgweTnZ0NwFNPPRWyib5AnepRPHl+B4ac1JQnv1jOsM+X85+fNvLQuW04vWUi+3L8knB23h/J96CboHOcJFyQkAvbHWE8t5Q/5qoW4SMm0ke1SB/RET7Cw4TI8DDCw4QIXxgxkeFE+Jxh5yGEu8ORfsMFbcJ9QqQ7LbxwuaLLR/jCCA8LIzJcCA9z11UwHB5GhLvtCDeO7XuzWZeZxbrMvazLzGJt5l7mrt/Bp2l//JxGBBrEVys88vf/W79GtJ0FlIFKcc/YYLo8z5ReZX79VJWZKzN48osVrMss/XX3UeFhxEaFFyblgsQcGxlOtciCaeHuNB/VIsP/aBfhc5YtaBfhtovyER3uIyys8ibAfdm5rN+2l3WZe1lb8EGwzfm7z+92kTGRPpLdM4Dmie6ZQEIszRJjiYm041R/x3x5pTFVlYhwRut6nNoikf8uSGfr7wcPkax9VIsIJzbK505zkruvEifj8hQTGU67BvG0axBfZLqqsvX3g27yd84A1m3by8JfdvL54i1FSkwN4qP9SkDuh0Hd6hxXI7pSfwiWB0v0xgQgwhfG4K6NvQ4j5IkI9eOjqR8fTc/jE4rMO5CTV3gWsC4zi3XbnLOB/y7YTJbfTWeiI8JITvijBNS84LuAxFiqR1XNlFc1n7UxptKJjvDR5rgatDmuRpHpqkrmnoPu0X8WazOcv0vSdzN5ya/4f/VRr0YUzROr06FhPKe3TCSlaW0iw0P/50SW6I0xlZqIULdGNHVrRNOjedGbzRzIyeOXHftYm/HHGcDazL2M+n49b3y7jthIHycfn0CvVon0alWXhjWrefQsypclemNMyIqO8NGyXhwt6xX98VvWwVzmrNnGrFWZfLMyk2nLtwLQom51Tm/pJP2uybWICg+Nyz4t0RtjqpzqUeGc3a4+Z7erj6qyNjOLWSszmbUykw9+2Mjbs9cTE+nj5OZ1ChN/o9qV905llugD5PP56NChA7m5uSQnJzN69Ghq1qx5zOvdsGED/fv3Z+nSpWUQ5R8ee+wx3nrrLQpu5NK3b1+GDx9eptsokJaWxpYtWzj33HPLZf3GlCcR4fi6cRxfN47rT23G3oO5/Lhuu5P4V2UwfUUGsIxmibH0almXXq0S6ZZcm+iIynO0b4k+QNWqVSMtLQ1w+pwZOXIkDz30kMdRHd7f//537r333lIvl5eXh88X+Js4LS2N1NRUS/QmJMRGhXNmm3qc2aYeqsq6bXvdo/0M/vPTRkZ9v57oiDB6NKtDr1ZO4m9SJ7h7dK18iX7yUPhtSdmus34H6Bf40W6PHj1YvHgx4HRjMGjQIHbu3ElOTg5PPvkkgwYNYsOGDfTr149TTjmFOXPm0LBhQz777DOqVavG/Pnzufbaa4mJiSnSSdiBAwe4+eabSU1NJTw8nOeff57evXvz3nvv8emnn5KXl8fSpUu55557yM7OZvTo0URFRfHll1/+qcO0Q5kxYwb33nsvubm5dO3alddee42oqCiaNm3Ktddey9SpU7ntttvo2rUrt956K5mZmcTExPDWW2/RunVrxo8fz+OPP47P5yM+Pp7p06fzyCOPsH//fmbPns0DDzzA4MGDS7f/jQlSIuJeolmd605JZn92nnu0n8GsVZnMXLkMgOSEWE5vmcjprRLp0axO0B3th/51RWUsLy+PGTNmMHDgQACio6OZOHEiCxYsYObMmdxzzz2FvVquXr2aW2+9lWXLllGzZk0++eQTAK655hpefvllfvjhhyLrHjlyJODcHeqjjz7iqquuKryx9tKlS/nwww+ZO3cuDz30EDExMSxcuJAePXoc8m5UL7zwQuFdpqZMmcKBAwe4+uqr+fjjj1myZAm5ubm89tprhe2jo6OZPXs2l156KTfccAOvvPIK8+fPZ8SIEdxyyy0ADBs2jClTprBo0SImTZpEZGQkw4YNY/DgwaSlpVmSNyGtWqSP3q3r8vig9nxzX29m3tuLxwa0pUmdGD6a+wvXvDuPTo9P5apRc3n3+/Wsy8wiGHofqHxH9KU48i5LBX3dbNiwgRNPPJGzzjoLcK7hffDBB/n2228JCwtj8+bNbN3qfINfcPs++KMr4eJdDw8ZMoTJkycDMHv2bG6//XYAWrduTZMmTVi1ahUAvXv3Ji4ujri4OOLj4xkwYADg9FNTcHZRXPHSzaJFi0hOTqZly5bAHyWou+66C6AwSWdlZTFnzpwiXSIfPOjcBrhnz55cffXVXHLJJYXdJBtTVSUnxJKckMzVPZM5kOMc7X/jXsnz+P+WA9C4dox7+WYiPZoleNKBW+VL9B4pqNHv3r2b/v37M3LkSO644w7GjBlDZmYm8+fPJyIigqZNmxYehRd0IwzOl7n79+9HVQ/ZSdPhPvn91xUWFlY4HhYWFnAXxUc6sijoujg/P5+aNWsWfifh7/XXX+enn37iiy++oHPnziW2MaYqio7wuTX7ujAAftm+j1mrMpi1MpNxqZv44IeNRIaH0T25duGVPM0TYyuk0zYr3ZRSfHw8L7/8MiNGjCAnJ4fdu3dTt25dIiIimDlzJhs3bjzs8jVr1iQ+Pp7Zs2cDMGbMmMJ5p512WuH4qlWr+OWXX2jVqlWZxd66dWs2bNjAmjVrAA7Z7XGNGjVITk5m/PjxgPMBsWjRIgDWrl1L9+7dGTZsGAkJCWzatIm4uDj27NlTZnEaEwoa14nhrz2aMurqrqQ9cjajr+vGkJOasGXXfp78YgV9nv+GU5+ZyUMTlzBt+Vb2HizdPSVKwxL9UejSpQudOnVi7NixXHHFFaSmppKSksKYMWNo3br1EZd/9913ufXWW+nRowfVqv3xS7xbbrmFvLw8OnTowODBg3nvvfeKHMkfq+joaN59910uvvhiOnToQFhYGDfddFOJbceMGcM777xDp06daNeuHZ999hkA9913Hx06dKB9+/acdtppdOrUid69e7N8+XI6d+7Mxx9/XGbxGhMqoiN8nNoikX/0b8uMe3rx3f29eeL89rSuX4OJCzfztw9S6TJsGrd9uKBctm/dFJtyZ6+fMYd2MDeP1A07mbUyg8jwMO4758gHiyWxboqNMSZIRYX76Hl8wp966yxLVroxxpgQV2kSfbCVmExg7HUzxnuVItFHR0ezfft2SxqVjKqyfft2oqOjvQ7FmCqtUtTok5KSSE9PJzMz0+tQTClFR0eTlJTkdRjGVGkBJXoR6Qu8BPiAt1V1eLH5pwEvAh2BS1V1gt+8p4Hz3NEnVLXU199FRESQnJxc2sWMMcYQQOlGRHzASKAf0Ba4TETaFmv2C3A18GGxZc8DTgA6A92B+0SkBsYYYypMIDX6bsAaVV2nqtnAWGCQfwNV3aCqi4H8Ysu2Bb5R1VxV3QssAvqWQdzGGGMCFEiibwhs8htPd6cFYhHQT0RiRCQB6A00Kt5IRG4QkVQRSbU6vDHGlK1AavQl9bgT0OUvqjpVRLoCc4BM4AfgTx06qOqbwJsAIpIpIofvMObwEoBtx7B8ebG4SsfiKh2Lq3RCMa4mh5oRSKJPp+hReBKwJdAtq+o/gX8CiMiHwOojtE8MdN0lEZHUQ/0M2EsWV+lYXKVjcZVOVYsrkNLNPKCFiCSLSCRwKTApkJWLiE9E6rjDHXGuypl6tMEaY4wpvSMe0atqrojcBkzBubxylKouE5FhQKqqTnLLMxOBWsAAEXlcVdsBEcB3bn/LvwNXqmr59cVpjDHmTwK6jl5VvwS+LDbtEb/heTglneLLHcC58qYivVnB2wuUxVU6FlfpWFylU6XiCrpuio0xxpStStHXjTHGmKNnid4YY0JcyCR6ERklIhkistTrWAqISCMRmSkiK0RkmYjc6XVMACISLSJzRWSRG9fjXsfkz71aa6GIfO51LAVEZIOILBGRNBFJPfISFUNEaorIBBH52X2f9fA6JgARaeXuq4LH7yJyVxDE9Xf3Pb9URD4SkaDoWlVE7nRjWlYe+ylkavRux2pZwAeq2t7reABE5DjgOFVdICJxwHzgfFVd7nFcAsSqapaIRACzgTtV9Ucv4yogIncDKUANVe3vdTzgJHogRVWD6kc2IvI+8J2qvu1e/hyjqru8jsuf21/WZqC7qh7LjyGPNY6GOO/1tqq6X0TGAV+q6ntexeTG1R6na5luQDbwFXCzqh72N0elETJH9Kr6LbDD6zj8qeqvqrrAHd4DrCDw7iPKjTqy3NEI9xEUn/gikoTT2+nbXscS7NwOAk8D3gFQ1exgS/KuM4G1XiZ5P+FANREJB2IoxY8/y1Eb4EdV3edefv4NcEFZbiBkEn2wE5GmQBfgJ28jcbjlkTQgA5imqkERF0531/fz5w7yvKbAVBGZLyI3eB2MqxlO1yLvuqWut0Uk1uugSnAp8JHXQajqZmAETm+7vwK7VTUYfsC5FDhNROqISAxwLiX0CXYsLNFXABGpDnwC3KWqv3sdD4Cq5qlqZ5zfP3RzTx89JSL9gQxVne91LCXoqaon4HTXfatbKvRaOE434K+pahdgLzDU25CKcstJA4HxQRBLLZyed5OBBkCsiFzpbVSgqiuAp4FpOGWbRZTQJ9ixsERfztwa+CfAGFX9r9fxFOee6s8iOLqP7gkMdOvhY4EzROQ/3obkUNUt7t8MnF+Bd/M2IsDphyrd72xsAk7iDyb9gAWqutXrQIA+wHpVzVTVHOC/wMkexwSAqr6jqieo6mk4Jegyq8+DJfpy5X7p+Q6wQlWf9zqeAiKSKCI13eFqOP8AP3sbFajqA6qapKpNcU73v1ZVz4+4RCTW/TIdtzRyNs7ptqdU9Tdgk4i0ciedCXj6RX8JLiMIyjauX4CT3G7TBWd/rfA4JgBEpK77tzFwIWW8zyrFPWMDISIfAb2ABBFJBx5V1Xe8jYqewBBgiVsPB3jQ7VLCS8cB77tXQ4QB41Q1aC5lDEL1gIlun03hwIeq+pW3IRW6HRjjlkjWAdd4HE8ht958FnCj17EAqOpPIjIBWIBTGllI8HSF8InbAWQOcKuq7izLlYfM5ZXGGGNKZqUbY4wJcZbojTEmxFmiN8aYEGeJ3hhjQpwlemOMCXGW6I0xJsRZojfGmBD3/7+WzAmznx3qAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def error(y_pred, y):\n",
    "    return 1 - calc_acc(y_pred, y)\n",
    "\n",
    "X_train_s, X_val_s, y_train_s, y_val_s = tts(spam_X, spam_y, test_size=0.8, random_state=27)\n",
    "errors_tree = []\n",
    "errors_forest = []\n",
    "tree = DecisionTree(spam_features, spam_classes)\n",
    "forest = RandomForest(spam_features, spam_classes, 4)\n",
    "\n",
    "for i in range(1,10):\n",
    "    tree.fit(X_train_s, y_train_s,i)\n",
    "    forest.fit(X_train_s, y_train_s, i)\n",
    "    errors_tree.append(error(tree.predict(X_val_s), y_val_s))\n",
    "    errors_forest.append(error(forest.predict(X_val_s), y_val_s))\n",
    "    \n",
    "plt.plot(list(range(1,10)), errors_tree, label=\"Decision Tree\")\n",
    "plt.plot(list(range(1,10)), errors_forest, label=\"Random Forest\")\n",
    "plt.legend()\n",
    "plt.title(\"Validation Accuracy on Spam Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex, 1.0\n",
      "\t\tpclass, 3.0\n",
      "\t\t\t\tfare, 23.45\n",
      "\t\t\t\t\t\t(Died : 0.42142857142857143, Survived : 0.5785714285714286)\n",
      "\t\t\t\t\t\t(Died : 0.9, Survived : 0.1)\n",
      "\t\t\t\tembarked, 3.0\n",
      "\t\t\t\t\t\t(Died : 0.08, Survived : 0.92)\n",
      "\t\t\t\t\t\t(Died : 0.0, Survived : 1.0)\n",
      "\t\tcabin, 6.0\n",
      "\t\t\t\tage, 4.0\n",
      "\t\t\t\t\t\t(Died : 0.35714285714285715, Survived : 0.6428571428571429)\n",
      "\t\t\t\t\t\t(Died : 0.8651252408477842, Survived : 0.1348747591522158)\n",
      "\t\t\t\tage, 18.0\n",
      "\t\t\t\t\t\t(Died : 0.0, Survived : 1.0)\n",
      "\t\t\t\t\t\t(Died : 0.6605504587155964, Survived : 0.3394495412844037)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample visualization of Decision Tree structure\n",
    "titanic = DecisionTree(titanic_features, titanic_classes)\n",
    "titanic.fit(titanic_X, titanic_y, 3)\n",
    "print(titanic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will generate our predictions on a test set, and write them to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write our results to CSV file\n",
    "def results_to_csv(y_test, name):\n",
    "    y_test = y_test.astype(int)\n",
    "    df = pd.DataFrame({'Category': y_test})\n",
    "    df.index += 1 # Ensures that the index starts at 1. \n",
    "    csv_name = name + '.csv'\n",
    "    df.to_csv(csv_name, index_label='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit decision tree and random forest to both datasets, then generate predictions\n",
    "tree_t = DecisionTree(titanic_features, titanic_classes)\n",
    "tree_s = DecisionTree(spam_features, spam_classes)\n",
    "forest_t = RandomForest(titanic_features, titanic_classes, 10)\n",
    "forest_s = RandomForest(spam_features, spam_classes, 10)\n",
    "tree_t.fit(titanic_X,titanic_y, 10)\n",
    "tree_s.fit(spam_X,spam_y, 3)\n",
    "forest_t.fit(titanic_X, titanic_y, 3)\n",
    "forest_s.fit(spam_X, spam_y,3)\n",
    "titanic_test_tree = tree_t.predict(titanic_test)\n",
    "spam_test_tree = tree_s.predict(spam_test)\n",
    "titanic_test_forest = forest_t.predict(titanic_test)\n",
    "spam_test_forest = forest_s.predict(spam_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a CSV file for each set of predictions\n",
    "results_to_csv(titanic_test_tree, \"titanic_tree\")\n",
    "results_to_csv(spam_test_tree, \"spam_tree\")\n",
    "results_to_csv(spam_test_forest, \"spam_forest\")\n",
    "results_to_csv(titanic_test_forest, \"titanic_forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
