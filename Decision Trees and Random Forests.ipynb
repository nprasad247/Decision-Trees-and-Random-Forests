{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is an implementation of a decision tree and random forest for classification on the Titanic and Spam datasets. The decision tree calculates a split that maximizes information gain, and builds a tree structure maintaining class probabilities. Traversal stops when a class reaches a probability of 1.0, or we reach a specified maximum depth. The random forest implements the bagging ensemble method, training individual trees on random subsets of the data, then outputting the mode of all predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import genfromtxt\n",
    "import scipy.io\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "%matplotlib inline\n",
    "\n",
    "class Node:\n",
    "    \"\"\"\n",
    "    A single node in the decision tree:\n",
    "    \n",
    "    left: pointer to left subtree\n",
    "    right: pointer to right subtree\n",
    "    split_rule: A pair containing a feature and threshold to split on (f, t)\n",
    "    depth: The current depth of the node in the tree\n",
    "    probs: Probability of each class label at this node (only at leaves)\n",
    "    \"\"\"\n",
    "    def __init__(self, left, right, rule, depth, probs = None):\n",
    "        self.split_rule = rule\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.depth = depth\n",
    "        self.probs = probs\n",
    "        \n",
    "    def is_leaf(self):\n",
    "        return self.probs is not None # Only the leaf nodes will store probabilities\n",
    "    \n",
    "class DecisionTree:\n",
    "    \n",
    "    def __init__(self, features, classes):\n",
    "        self.classes = classes\n",
    "        self.class_indices = np.arange(len(classes))\n",
    "        self.features = features\n",
    "        \n",
    "    def LeafNode(self, depth, probs):\n",
    "        \"\"\"\n",
    "        Leaf node for the decision tree. Has no children or split rule, just \n",
    "        current depth and class probabilities.\n",
    "        \"\"\"\n",
    "        return Node(None, None, None, depth, probs)\n",
    "    \n",
    "    def is_categorical(self, feature):\n",
    "        return self.features[feature] in ['pclass', 'sex', 'embarked']\n",
    "    \n",
    "    def calc_probs(self, y):\n",
    "        \"\"\"\n",
    "        Calculate the proportion of each class label within y.\n",
    "        \"\"\"\n",
    "        return np.array([np.mean([y == label * np.ones(len(y))]) for label in self.class_indices])\n",
    "        \n",
    "    def entropy(self, y):\n",
    "        \"\"\"\n",
    "        Calculates the entropy given all the labels\n",
    "        \"\"\"\n",
    "        return stats.entropy(self.calc_probs(y))\n",
    "\n",
    "    def information_gain(self, X, y, idx, thresh):\n",
    "        \"\"\"\n",
    "        Calculates information gain given a vector of features and a split threshold\n",
    "        \"\"\"\n",
    "        left, right = self.split(X, y, idx, thresh)\n",
    "        left_H = self.entropy(y[left]) if list(left) else 0\n",
    "        right_H = self.entropy(y[right]) if list(right) else 0\n",
    "        H_after = (len(left) * left_H + len(right) * right_H) / len(y)\n",
    "        return self.entropy(y) - H_after\n",
    "\n",
    "    def split(self, X, y, idx, thresh):\n",
    "        \"\"\"\n",
    "        Returns a split of the dataset given an index of the feature and\n",
    "        a threshold for it\n",
    "        \"\"\"\n",
    "        left, right = [], []\n",
    "        for i in range(len(X)):\n",
    "            point = X[i]\n",
    "            comparison = lambda x,y : (x == y if self.is_categorical(idx) else x < y)\n",
    "            \n",
    "            if comparison(point[idx], thresh):\n",
    "                left.append(i)\n",
    "                \n",
    "            else:\n",
    "                right.append(i)\n",
    "                \n",
    "        return np.array(left), np.array(right)\n",
    "        \n",
    "    def segmenter(self, X, y):\n",
    "        \"\"\"\n",
    "        Compute entropy gain for all single-dimension splits,\n",
    "        return the feature and the threshold for the split that\n",
    "        has maximum gain\n",
    "        \"\"\"\n",
    "        best_gain = -float('inf')\n",
    "        best_pair = None\n",
    "        for i in range(len(self.features)):\n",
    "            thresholds = list(set(X[:,i]))\n",
    "            \n",
    "            for threshold in thresholds:\n",
    "                curr_gain = self.information_gain(X, y, i, threshold)\n",
    "                \n",
    "                if curr_gain > best_gain:\n",
    "                    best_pair = (i, threshold)\n",
    "                    best_gain = curr_gain\n",
    "                    \n",
    "        return best_pair\n",
    "             \n",
    "    def fit(self, X, y, max_depth):\n",
    "        \"\"\"\n",
    "        Fit the model to a training set using the grow_tree helper function.\n",
    "        \"\"\"\n",
    "        self.root = self.grow_tree(X, y, 0, max_depth)\n",
    "        \n",
    "    def grow_tree(self, X, y, curr_depth, max_depth):\n",
    "        probs = self.calc_probs(y)\n",
    "        feature, threshold = self.segmenter(X, y)\n",
    "        left, right = self.split(X, y, feature, threshold)\n",
    "        X_left = None if not list(left) else X[left]\n",
    "        y_left = None if not list(left) else y[left]\n",
    "        X_right = None if not list(right) else X[right]\n",
    "        y_right = None if not list(right) else y[right]\n",
    "        \n",
    "        if 1.0 in probs or curr_depth == max_depth:\n",
    "            return self.LeafNode(curr_depth, probs)\n",
    "        \n",
    "        if X_left is not None:\n",
    "            left_node = self.grow_tree(X_left, y_left, curr_depth + 1, max_depth)\n",
    "            \n",
    "        else:\n",
    "            left_node = self.LeafNode(curr_depth + 1, probs)\n",
    "            \n",
    "        if X_right is not None:\n",
    "            right_node = self.grow_tree(X_right, y_right, curr_depth + 1, max_depth)\n",
    "            \n",
    "        else:\n",
    "            right_node = self.LeafNode(curr_depth + 1, probs)\n",
    "            \n",
    "        return Node(left_node, right_node, (feature, threshold), curr_depth)\n",
    "   \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the labels for input data \n",
    "        \"\"\"\n",
    "        y = []\n",
    "        for point in X:\n",
    "            node = self.root\n",
    "            \n",
    "            while node is not None and not node.is_leaf():\n",
    "                feature, threshold = node.split_rule\n",
    "                comparison = lambda x,y : (x == y if self.is_categorical(feature) else x < y)\n",
    "                node = node.left if comparison(point[feature], threshold) else node.right\n",
    "                \n",
    "            y.append(np.argmax(node.probs))\n",
    "            \n",
    "        return np.array(y)\n",
    "                    \n",
    "        \n",
    "    def generateString(self, node):\n",
    "        \"\"\"\n",
    "        Visualization method for the tree\n",
    "        \"\"\"\n",
    "        if not node:\n",
    "            return \"\"\n",
    "        \n",
    "        if node.is_leaf():\n",
    "            class_probs = str(dict(zip(self.classes, node.probs)))\n",
    "            return \"\\t\" * node.depth + class_probs + '\\n'\n",
    "        \n",
    "        fidx, thresh = node.split_rule\n",
    "        return \"\\t\" * node.depth + f\"{self.features[fidx]}, {thresh}\\n\" \\\n",
    "             + \"\\t\" * node.left.depth \\\n",
    "             + self.generateString(node.left) \\\n",
    "             + \"\\t\" * node.right.depth \\\n",
    "             + self.generateString(node.right)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.generateString(self.root)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    \n",
    "    def __init__(self, features, classes, num_trees):\n",
    "        \"\"\"\n",
    "        Initialization of a random forest\n",
    "        \"\"\"\n",
    "        self.trees = np.array([DecisionTree(features, classes) for _ in range(num_trees)])\n",
    "        \n",
    "    def fit(self, X, y, max_depth):\n",
    "        \"\"\"\n",
    "        Fit the model to a training set\n",
    "        \"\"\"\n",
    "        for tree in self.trees:\n",
    "            X_t, y_t = [], []\n",
    "            \n",
    "            for _ in range(len(y)):\n",
    "                idx = np.random.randint(len(y))\n",
    "                X_t.append(X[idx])\n",
    "                y_t.append(y[idx])\n",
    "            \n",
    "            tree.fit(np.array(X_t), np.array(y_t), max_depth)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the labels for input data \n",
    "        \"\"\"\n",
    "        predictions = np.array([tree.predict(X) for tree in self.trees])\n",
    "        final_predictions = np.array([stats.mode(predictions[:, i])[0][0] for i in range(len(predictions[0]))])\n",
    "        return final_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perfomance Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will preprocess the data to encode categorical values and fill in missing values. Then, we will train our models and measure their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nprasad/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:40: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "/Users/nprasad/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:41: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n"
     ]
    }
   ],
   "source": [
    "# Check if s is a numerical value\n",
    "def is_numeric(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except (ValueError, TypeError):\n",
    "        return False\n",
    "    \n",
    "# Preprocess the data by converting from strings to floats, and encoding categorical data with the LabelEncoder      \n",
    "def process_data(features, dataset):\n",
    "    for i in range(len(features)):\n",
    "            column = dataset[:,i]\n",
    "            \n",
    "            for j in range(len(column)):\n",
    "                \n",
    "                if column[j] == '':\n",
    "                    values = np.array([x for x in column if x != ''])\n",
    "                    \n",
    "                    if all(list(map(is_numeric, values))):\n",
    "                        values = values.astype(np.float64)\n",
    "                        column[j] = np.mean(values)\n",
    "                        \n",
    "            dataset[:,i] = column\n",
    "            # Label encoding for categorical features\n",
    "            le = LabelEncoder()\n",
    "            \n",
    "            if not is_numeric(dataset[0,i]):\n",
    "                le.fit(dataset[:,i])\n",
    "                dataset[:,i] = le.transform(dataset[:,i])\n",
    "    \n",
    "    return dataset.astype(np.float64)\n",
    "\n",
    "\"\"\"\n",
    "Read in the datasets from given files and run preprocessing.\n",
    "\"\"\"\n",
    "def generate_data(dataset):\n",
    "    # The titanic dataset requires preprocessing to convert categorical data and fill in missing values\n",
    "    if dataset == \"titanic\":\n",
    "    # Load titanic data       \n",
    "        data = genfromtxt('titanic_training.csv', delimiter=',', dtype=None)\n",
    "        test_data = genfromtxt('titanic_testing_data.csv', delimiter=',', dtype=None)\n",
    "        y = data[1:, 0]\n",
    "        class_names = [\"Died\", \"Survived\"]\n",
    "        features = data[0].astype(np.str)\n",
    "        data = process_data(features, data[1:].astype(np.str))\n",
    "        test_features = test_data[0].astype(np.str)\n",
    "        test_data = process_data(test_features, test_data[1:].astype(np.str))\n",
    "        y = y.astype(np.str)\n",
    "        empty_indices = [i for i in range(len(y)) if y[i] == '']\n",
    "        # Remove the indices with empty data\n",
    "        for i in empty_indices:\n",
    "            data = np.delete(data,i,0)\n",
    "            y = np.delete(y,i)\n",
    "        y = y.astype(np.int)\n",
    "    # The spam dataset does not require the above preprocessing: simply load the data    \n",
    "    elif dataset == \"spam\":\n",
    "        features = [\n",
    "        \"pain\", \"private\", \"bank\", \"money\", \"drug\", \"spam\", \"prescription\",\n",
    "        \"creative\", \"height\", \"featured\", \"differ\", \"width\", \"other\",\n",
    "        \"energy\", \"business\", \"message\", \"volumes\", \"revision\", \"path\",\n",
    "        \"meter\", \"memo\", \"planning\", \"pleased\", \"record\", \"out\",\n",
    "        \"semicolon\", \"dollar\", \"sharp\", \"exclamation\", \"parenthesis\",\n",
    "        \"square_bracket\", \"ampersand\"\n",
    "        ]\n",
    "        assert len(features) == 32\n",
    "\n",
    "    # Load spam data\n",
    "        data = scipy.io.loadmat('spam_data.mat')\n",
    "        X = data['training_data']\n",
    "        y = np.squeeze(data['training_labels'])\n",
    "        test_data = data['test_data']\n",
    "        class_names = [\"Ham\", \"Spam\"]\n",
    "        data = X\n",
    "    return data, y, test_data, features, class_names\n",
    "         \n",
    "    \n",
    "\n",
    "titanic_X, titanic_y, titanic_test, titanic_features, titanic_classes = generate_data(\"titanic\")\n",
    "spam_X, spam_y, spam_test, spam_features, spam_classes = generate_data(\"spam\")\n",
    "titanic_X = np.delete(titanic_X,0,1)\n",
    "titanic_features = titanic_features[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we measure the performance of both models through training and validation accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and validate both models, outputting training and validation accuracies\n",
    "X_train_t, X_val_t, y_train_t, y_val_t = tts(titanic_X, titanic_y, test_size=0.8, random_state=42)\n",
    "X_train_s, X_val_s, y_train_s, y_val_s = tts(spam_X, spam_y, test_size=0.8, random_state=42)\n",
    "titanic_tree = DecisionTree(titanic_features, titanic_classes)\n",
    "titanic_forest = RandomForest(titanic_features, titanic_classes, 5)\n",
    "spam_tree = DecisionTree(spam_features, spam_classes)\n",
    "spam_forest = RandomForest(spam_features, spam_classes, 5)\n",
    "titanic_tree.fit(X_train_t, y_train_t, 10)\n",
    "titanic_forest.fit(X_train_t, y_train_t, 10)\n",
    "spam_tree.fit(X_train_s, y_train_s, 10)\n",
    "spam_forest.fit(X_train_s, y_train_t, 10)\n",
    "titanic_tree_pred_tr = titanic_tree.predict(X_train_t)\n",
    "titanic_tree_pred_va = titanic_tree.predict(X_val_t)\n",
    "spam_tree_pred_tr = spam_tree.predict(X_train_s)\n",
    "spam_tree_pred_va = spam_tree.predict(X_val_s)\n",
    "titanic_forest_pred_tr = titanic_forest.predict(X_train_t)\n",
    "titanic_forest_pred_va = titanic_forest.predict(X_val_t)\n",
    "spam_tree_forest_tr = spam_forest.predict(X_train_s)\n",
    "spam_tree_forest_va = spam_forest.predict(X_val_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy for Titanic with Decision Tree: 0.9547738693467337\n",
      "Validation accuracy for Titanic with Decision Tree: 0.74\n",
      "Training accuracy for Titanic with Random Forest: 0.9547738693467337\n",
      "Validation accuracy for Titanic with Random Forest: 0.74375\n",
      "Training accuracy for Spam with Decision Tree: 0.8558994197292069\n",
      "Validation accuracy for Spam with Decision Tree: 0.7982116964717255\n",
      "Training accuracy for Spam with Random Forest: 0.6247582205029013\n",
      "Validation accuracy for Spam with Random Forest: 0.5988400193330111\n"
     ]
    }
   ],
   "source": [
    "def calc_acc(pred, actual):\n",
    "    return np.mean(pred == actual)\n",
    "\n",
    "training_acc_titanic_tree = calc_acc(titanic_tree_pred_tr, y_train_t)\n",
    "validation_acc_titanic_tree = calc_acc(titanic_tree_pred_va, y_val_t)\n",
    "training_acc_titanic_forest = calc_acc(titanic_forest_pred_tr, y_train_t)\n",
    "validation_acc_titanic_forest = calc_acc(titanic_forest_pred_va, y_val_t)\n",
    "training_acc_spam_tree = calc_acc(spam_tree_pred_tr, y_train_s)\n",
    "validation_acc_spam_tree = calc_acc(spam_tree_pred_va, y_val_s)\n",
    "training_acc_spam_forest = calc_acc(spam_tree_forest_tr, y_train_s)\n",
    "validation_acc_spam_forest = calc_acc(spam_tree_forest_va, y_val_s)\n",
    "print(f\"Training accuracy for Titanic with Decision Tree: {training_acc_titanic_tree}\")\n",
    "print(f\"Validation accuracy for Titanic with Decision Tree: {validation_acc_titanic_tree}\")\n",
    "print(f\"Training accuracy for Titanic with Random Forest: {training_acc_titanic_forest}\")\n",
    "print(f\"Validation accuracy for Titanic with Random Forest: {validation_acc_titanic_forest}\")\n",
    "print(f\"Training accuracy for Spam with Decision Tree: {training_acc_spam_tree}\")\n",
    "print(f\"Validation accuracy for Spam with Decision Tree: {validation_acc_spam_tree}\")\n",
    "print(f\"Training accuracy for Spam with Random Forest: {training_acc_spam_forest}\")\n",
    "print(f\"Validation accuracy for Spam with Random Forest: {validation_acc_spam_forest}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we plot the validation error as a function of tree depth for both the decision tree and random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation Error on Spam Dataset')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd3yV5fnH8c+VRSAkYa+EEWRDJgFBBLSggjLEioATV7XWn9tq1SrS1jqrVqy21qooZYNQBRdOVJAQAoQ9BDIYASQJGWTdvz+eJ+EQAmSc5Dk5ud6vV16c88zrnITvuc/9jFuMMSillPJePk4XoJRSqnZp0CullJfToFdKKS+nQa+UUl5Og14ppbycBr1SSnk5DXovJiJdRMSIiJ/9fLmI3FSZZauxr8dE5N81qVcpVTs06D2YiHwqItMrmD5eRA5UNZSNMaONMe+5oa6LRCS13LafMcbcVtNtV7CvqSJSLCLHy/10cPe+6or9+0sSkSwROSwiK0SkiwfU9bWI5ItItl3bWhF5VEQaVWEbRkS61Waddbkfb6FB79neBW4QESk3/QZgljGmqO5LcsSPxpim5X7Syy9U0Qdfdb6hiIhvdQutxLa7ATOBB4FQIAL4B1BSW/usoruNMcFAe6waJwPLKvgbVPWIBr1n+xBoAQwtnSAizYExWGGBiFwhIuvsFliKiEw708bsFttt9mNfEXnRblHuBq4ot+zNIrLFbt3tFpE77OlBwHKgg2vrWkSmicgHLuuPE5FNInLM3m9vl3l7ROQhEdkgIpkiMldEAqvzBtnbekRENgA5IuJ3hmm97TqO2XWNc9nGuyLyhogsE5Ec4OIK9tNBRJaKyFER2Skit7vMmyYi80Rkpv1+bRKR+DOUHAP8bIxZYSzZxpiFxph9LttaYL8n2SKSKCLRLvt6VER22fM2i8gEl3lTReR7EXnZfp27ReQCe3qKiBw6U9ddecaYHGPM18A4YDD234eIDBSRH+3t7xeRGSISYM/71l59vf13MUlEmovIRyKSISK/2I/Dy9W82349P4vIdS7zbrH/Bn8R69tt5zPtpzKvqUEzxuiPB/8AbwH/dnl+B5Dk8vwiIBLrQzsKOAhcac/rAhjAz37+NXCb/fhOYCvQEevD5Ktyy14BnAcIMBzIBeJc9plars5pwAf24x5ADnAJ4A/8HtgJBNjz9wA/AR3sfW8B7jzD658KrDzL+7MHSLJfR+OKptk17AQeAwKAXwHZQE97+XeBTGCI/T4GVrCfb7Ba3oFYYZ0BjHB57fnA5YAv8Fdg1Rnq7Wov+zLWB0rTCt7HQuBqu+6HgJ8Bf3v+RPt98wEm2e9ze5f3qgi42a7jz8A+4HWgEXCp/bqbnqG2sr+PctO/BZ6zH/cHBgF+WH9fW4D7XJY1QDeX5y2BXwNNgGBgPvChPS8IyHL5PbQH+tqPr7R/Z73tfT0B/HCm/ejPOXLE6QL05xy/ILjQDqHSEPseuP8sy78CvGw/7sKZg/5LXMLVDoGyZSvY7ofAvfbjizh70P8RmOcyzwdIAy6yn+8BrneZ/zzw5hn2Wxpex1x+drnM3wPcUm6dU6ZhfSM6APi4TJsNTLMfvwvMPMt72hEoBoJdpv0VeNfltX/hMq8PkHeW7Q0C5mF9WOTb+2/qsq1VLsv6APuBoWfYVhIw3uW92uEyL9L+nbZ1mXYEiDnDtsr+PspNnwO8dYZ17gMWuzw/awBjfUj+Yj8Osn+fv8b++3ZZbjlwa7n3IRfoXJn96M+pP9p14+GMMSuxAmG8iHQFBgD/LZ0vIueLyFf2V+NMrJZ6q0psugOQ4vJ8r+tMERktIqvsropjWK3Vymy3dNtl2zPGlNj7CnNZ5oDL41yg6Vm2t8oY08zl57xy81MqWMd1Wgcgxa6j1N5y9VS0Ddf1jxpjss+yfvnXE3im4wPGmFXGmGuMMa2xPoSGAY9XVItdc6pdAyJyo1gHco/Zv5d+nPp7OejyOM/eRvlpZ3uvKxIGHLX338PufjkgIlnAM5zl70JEmojIP0Vkr738t0AzEfE1xuRgfSu5E9gvIh+LSC971c7Aqy6v8yjWt8uwivajzk6Dvn6YCdyIdRD2s3L/cf8LLAU6GmNCgTex/kOcy36slmqpTqUPxDrLYiHwIlZrsBmwzGW757rlaTrWf9TS7Ym9r7RK1FUdFdXjOi0d6Cgirn/vncrVc7bXlA60EJHgs6xfLcaYNcAirMAuVfZ7sWsOB9LtPuq3gLuBlvbvJZnK/b6rRUQ6YnXXfGdPegOry6+7MSYEqzvsbPt/EOgJnG8vP6x00wDGmE+NMZdgddtsxXp9YH3Y3VHuA76xMeYHN768BkODvn6YCYwEbgfKnx4ZjNXazBeRgcC1ldzmPOAeEQkX6wDvoy7zArD6dDOAIhEZjdW1U+og0FJEQs+y7StEZISI+GP9Zz8BOPWfdDVWX/bvRcRfRC4CxmJ1SZyTMSYFq/a/ikigiEQBtwKzqlqIiFwoIreLSBv7eS+sA56rXBbrLyJX2d8I7sN671ZhdXUYrN8LInIzp35AuI3dEh8OLME6nrLMnhWM1a9+3K79t+VWPYh1HAKX5fOAYyLSAnjKZR9txTpoH4T1Go9jdZGB1WD5g4j0tZcNFZGJZ9mPOgsN+nrAGLMHK2iCsFrvru4CpotINvAkVshWxlvAp8B6IBGrVVm6v2zgHntbv2B9eCx1mb8Vq497t/3V+pRz2o0x24DrgdeAw1ihOtYYU1DJ2sobLKefRz+gsivb+x0HjLbr+Qdwo/06KmsK1jGPdGAx8JQx5vMqrF/qmF3LRhE5Dnxib+95l2WWYHVp/IL1Le4qY0yhMWYz8BLwI1bQRWIds3GnGfbf0kGs4z0LgVEu3V4PYf09ZGP9Dc0tt/404D377+IaexuNsd73VVivt5QPViMgHatrZjjW3zPGmMXAc8Acu8snGev3d6b9qLMQ+8CGUsoDiHV6bDdjzPVO16K8h7bolVLKy2nQK6WUl9OuG6WU8nLaoldKKS9XrVvS1qZWrVqZLl26OF2GUkrVK2vXrj1sX4R3Go8L+i5dupCQkOB0GUopVa+IyN4zzdOuG6WU8nIa9Eop5eU06JVSyst5XB+9UqpuFBYWkpqaSn5+vtOlqCoIDAwkPDwcf3//Sq+jQa9UA5WamkpwcDBdunRBdKTAesEYw5EjR0hNTSUiIqLS62nXjVINVH5+Pi1bttSQr0dEhJYtW1b5W5gGvVINmIZ8/VOd35nXBH125lF+fOs+UnZudLoUpZTyKF4T9CfycohO/S+HljzpdClKqUry9fUlJiaGvn37Eh0dzd/+9jdKSkrOvWIFnnzySb744oszzn/zzTeZOXNmdUsFYOPGjcTExBATE0OLFi2IiIggJiaGkSNH1mi7tc1rDsa2ateRH8OnMDjtXXZt+IHzoi5wuiSl1Dk0btyYpKQkAA4dOsS1115LZmYmTz/9dJW3NX369LPOv/POO6tVo6vIyMiyeqdOncqYMWO4+uqrT1uuqKgIPz/PiVevadED9Ln6j2QRxPHlT517YaWUR2nTpg3/+te/mDFjBsYYiouLefjhhxkwYABRUVH885//LFv2+eefJzIykujoaB591BoFc+rUqSxYsACARx99lD59+hAVFcVDDz0EwLRp03jxxRcBSEpKYtCgQURFRTFhwgR++eUXAC666CIeeeQRBg4cSI8ePfjuu++orC+++IKRI0cyefJkYmNjAXjvvfcYOHAgMTEx3HXXXWXfVpYvX87gwYOJi4tj0qRJ5OTk1PDdOzvP+chxg9Dmrfgx4mYG/zyDLas/pff5lzldklL1wtP/28Tm9Cy3brNPhxCeGtu3Sut07dqVkpISDh06xJIlSwgNDWXNmjWcOHGCIUOGcOmll7J161Y+/PBDVq9eTZMmTTh69Ogp2zh69CiLFy9m69atiAjHjh07bT833ngjr732GsOHD+fJJ5/k6aef5pVXXgGs1vhPP/3EsmXLePrpp8/aHVTeqlWr2Lx5M506dSI5OZnFixfzww8/4Ofnx29+8xvmzJnDyJEjefbZZ1mxYgVNmjThL3/5C6+++iqPPfZYld6rqvCqoAeIufpRDr/wAeaL6ZgBlyA+XvWlRSmvVzpGxmeffcaGDRvKWumZmZns2LGDL774gptvvpkmTZoA0KJFi1PWDwkJITAwkNtuu40rrriCMWPGnDI/MzOTY8eOMXz4cABuuukmJk48Oe74VVddBUD//v3Zs2dPlWofPHgwnTp1AqwW/po1a4iPjwcgLy+Pjh070qRJEzZv3swFF1jdywUFBVx44YVV2k9VeV3QNw4KZkPvuzh/yzOs/2Yh0RdPPPdKSjVwVW1515bdu3fj6+tLmzZtMMbw2muvcdllp34z/+STT856iqGfnx8//fQTK1asYM6cOcyYMYMvv/yy0jU0atQIsA4UFxUVVan+oKCgssfGGG655Rb+9Kc/nbLM4sWLGTVqFO+//36Vtl0TXtncjb3yXtKlLU1XPkNJcbHT5SilKiEjI4M777yTu+++GxHhsssu44033qCwsBCA7du3k5OTw6WXXsp//vMfcnNzAU7rujl+/DiZmZlcfvnlvPLKK2UHT0uFhobSvHnzsv73999/v6x1704jR45k3rx5HD58GIAjR46wb98+LrjgAr755ht2794NQE5ODjt27HD7/l15XYseIKBRIGkx9zFg3R9Y++m79L/8VqdLUkpVIC8vj5iYGAoLC/Hz8+OGG27ggQceAOC2225jz549xMXFYYyhdevWfPjhh4waNYqkpCTi4+MJCAjg8ssv55lnninbZnZ2NuPHjyc/Px9jDC+//PJp+33vvfe48847yc3NpWvXrrzzzjtuf22RkZE89dRTjBw5kpKSEvz9/XnzzTcZMGAAb7/9NpMmTaKgoACAZ555hu7du7u9hlIeN2ZsfHy8ccfAI8VFRaQ8E4uvKaL9Y+vx8w9wQ3VKeY8tW7bQu3dvp8tQ1VDR705E1hpj4ita3iu7bgB8/fz4ZdAjdDTpJC593elylFLKMV4b9AAxI69lm19POm98jfy82j1PVSmlPJVXB734+FB40RO05QhJi150uhyllHKEVwc9QL8Lx7GxUSw9d7xFdubRc6+glFJexuuDHqDRZU/TnGySF/7V6VKUUqrONYig7xE3nMSgoUTufZ9fMvY7XY5SStWpBhH0AC3HPE1j8tm2oOp3xVNK1Y7S2xT369ePsWPHVnhfmurYs2cP/fr1c8u2XE2bNo2wsLCyWxWX3lCtNiQlJbFs2TK3bKvBBH3n3v1JbHYZsQcWcDB1l9PlKKU4eZvi5ORkWrRoweuve/6p0Pfffz9JSUkkJSXx7LPPVnq94ipepa9BX01hE6YjlLB3kd7GWClPM3jwYNLS0gDrNgYjRowgLi6OyMhIlixZAlgt9d69e3P77bfTt29fLr30UvLy8gBYu3Yt0dHRDB48+JQPjPz8fG6++WYiIyOJjY3lq6++AuDdd9/lyiuvZOzYsURERDBjxgz+9re/ERsby6BBg067tcLZrFixgtjYWCIjI7nllls4ceIEAF26dGH69OlceOGFzJ8/n127djFq1Cj69+/P0KFD2bp1KwDz58+nX79+REdHM2zYMAoKCnjyySeZO3cuMTExzJ07t0bvrVfeAuFMOnTpyeo2E+h/aBEpO9bTsXu00yUp5RmWPwoH3DwMZ7tIGF25Fm9xcTErVqzg1lut25UEBgayePFiQkJCOHz4MIMGDWLcuHEA7Nixg9mzZ/PWW29xzTXXsHDhQq6//npuvvnmslsPP/zww2XbLg39jRs3snXrVi699FK2b98OQHJyMuvWrSM/P59u3brx3HPPsW7dOu6//35mzpzJfffdd1qtL7/8Mh988AEAzz33HMOHD2fq1KmsWLGCHj16cOONN/LGG2+UrRsYGMjKlSsBGDFiBG+++Sbdu3dn9erV3HXXXXz55ZdMnz6dTz/9lLCwMI4dO0ZAQADTp08nISGBGTNmVOfdP0WDatEDnPfraRTgz6Gl2qpXymml97pp2bIlR48e5ZJLLgGsOz8+9thjREVFMXLkSNLS0jh48CBA2fB9cPJWwuVvPXzDDTeU7WPlypVlz3v16kXnzp3Lgv7iiy8mODiY1q1bExoaytixYwHrPjVnukWxa9fNZZddxrZt24iIiKBHjx6Addvjb7/9tmz5SZMmAda3lB9++IGJEycSExPDHXfcwf791skhQ4YMYerUqbz11ltV7uKpjAbVogcdclCpClWy5e1upX30mZmZjBkzhtdff5177rmHWbNmkZGRwdq1a/H396dLly7k5+cDJ28jDNbB3Ly8PIwxZ7x18dnu5+W6LR8fn7LnPj4+lb5F8bnuF1Z66+KSkhKaNWt22t00wRrPdvXq1Xz88cfExMRUuExNNLgWPVhDDmbqkINKeYzQ0FD+/ve/8+KLL1JYWEhmZiZt2rTB39+fr776ir179551/WbNmhEaGlrWRTJr1qyyecOGDSt7vn37dvbt20fPnj3dVnuvXr3Ys2cPO3fuBM582+OQkBAiIiKYP38+YH1ArF+/HoBdu3Zx/vnnM336dFq1akVKSgrBwcFkZ2e7pcYGGfShzVuxueutROf9xJbVnzpdjlIKiI2NJTo6mjlz5nDdddeRkJBAfHw8s2bNolevXudc/5133uF3v/sdgwcPpnHjxmXT77rrLoqLi4mMjGTSpEm8++67p7TkayowMJB33nmHiRMnEhkZiY+PzxkHIp81axZvv/020dHR9O3bt+wg88MPP0xkZCT9+vVj2LBhREdHc/HFF7N582a3HIz12tsUn0teTjbHX4jksH8Hev1hpQ45qBocvU1x/aW3Ka6kxkHB7O5zF70LN7Hh6wVOl6OUUrWmwQY9QOz4e6whB7//qw45qJTyWg066AMaBZIeez/nFe9m3SfuH0pMKU/naV236tyq8ztr0EEPEHv57fzs05k2CS9RWHDC6XKUqjOBgYEcOXJEw74eMcZw5MgRAgMDq7RegzuPvjxfPz8yBz9KzPe/5aelrzPw6gecLkmpOhEeHk5qaioZGRlOl6KqIDAwkPDw8Cqt02DPunFlSkrY/sxgmhcdIuSRZAIbB9Xp/pVSqqZqfNaNiIwSkW0islNETrsvp4g8ICKbRWSDiKwQkc729M4islZEkkRkk4hUfHKpw8THh8KLn6ANR3XIQaWU1zln0IuIL/A6MBroA0wRkT7lFlsHxBtjooAFwPP29P3ABcaYGOB84FER6eCu4t2p35CxbGwUp0MOKqW8TmVa9AOBncaY3caYAmAOMN51AWPMV8aYXPvpKiDcnl5gjCk9wtmokvtzTOAoe8jBBc84XYpSSrlNZYI3DEhxeZ5qTzuTW4HlpU9EpKOIbLC38ZwxJr38CiLyGxFJEJEEJw8MdY8dRmLQUKL2vc/RQ2mO1aGUUu5UmaCv6JZwFR7BFZHrgXjghbIFjUmxu3S6ATeJSNvTNmbMv4wx8caY+NatW1eu8lrScux0AjnB9oV/crQOpZRyl8oEfSrQ0eV5OFBRq3wk8DgwzqW7pozdkt8EDK1eqXWjc684EpuPIvbAAg6k7HS6HKWUqrHKBP0aoLuIRIhIADAZWOq6gIjEAv/ECvlDLtPDRaSx/bg5MATY5q7ia0v4hKcRDPt0yEGllBc4Z9AbY4qAu4FPgS3APGPMJhGZLiLj7MVeAJoC8+1TKUs/CHoDq0VkPfAN8KIxxs3jlblf+849SWwzgbijy0jZsd7pcpRSqkb0gqkzOHwghSZv9GdLyAX0f/BDp8tRSqmz0tsUV0Ordh1ZH34t/bO/Yuf6750uRymlqk2D/iz6XP0EmQSRo0MOKqXqMQ36swht3ootXW8lOn8Nm1d94nQ5SilVLRr05xD969+TQXNkxdOYkhKny1FKqSrToD+Hk0MObtYhB5VS9ZIGfSXEjr+HNGlL0++f0SEHlVL1jgZ9JQQ0CmR/7AOcV/wziZ/8x+lylFKqSjToKyn28tv42acz7XTIQaVUPaNBX0mlQw6Gm/2sW/q60+UopVSladBXQfSIyWz1602X5NfIzz3udDlKKVUpGvRVID4+FF/8Rx1yUClVr2jQV1HfIVewIbA/PXf+W4ccVErVCxr01dD4smn2kIN/cboUpZQ6Jw36arCGHBxG1L4PdMhBpZTH06CvppZjn7aHHJzudClKKXVWGvTV1LlXHGubjyb2wEIdclAp5dE06Gug44Rp9pCDTzpdilJKnZEGfQ2cHHJwOfu2JzldjlJKVUiDvoa6Xz2NAvzJWKqDkyilPJMGfQ21bBvO+o7X0f/41+xcv9LpcpRS6jQa9G7Q1x5yMHf5NKdLUUqp02jQu0FIs5Zs6XorUflr2PzjcqfLUUqpU2jQu0nZkINfTtchB5VSHkWD3k2sIQd/Zw85OM/pcpRSqowGvRvFXVk65OCzOuSgUspjaNC7kX9Ao5NDDi5/2+lylFIK0KB3u7grbudnny60W/s3HXJQKeURNOjdzMfXl8wLrCEHE5fMcLocpZTSoK8N0b+axFa/3kRsmqFDDiqlHKdBXwtOHXLwBafLUUo1cBr0taR0yMFeOuSgUsphGvS1qPGop2nGcR1yUCnlKA36WtQ9ZiiJTXXIQaWUszToa1nLsX8ikBPsmPeE06UopRooDfpa1rlnDAmtJxCfsZjdyaudLkcp1QBVKuhFZJSIbBORnSLyaAXzHxCRzSKyQURWiEhne3qMiPwoIpvseZPc/QLqg15TniVLmpK39EG94ZlSqs6dM+hFxBd4HRgN9AGmiEifcoutA+KNMVHAAuB5e3oucKMxpi8wCnhFRJq5q/j6IrRlW7b3vY++BRtJXP4fp8tRSjUwlWnRDwR2GmN2G2MKgDnAeNcFjDFfGWNy7aergHB7+nZjzA77cTpwCGjtruLrk/gJ97HLtyvha54h93im0+UopRqQygR9GJDi8jzVnnYmtwKnjb4hIgOBAGBXBfN+IyIJIpKQkZFRiZLqH18/PwoufZa2HGH9nGlOl6OUakAqE/RSwTRT4YIi1wPxwAvlprcH3gduNsac1kltjPmXMSbeGBPfurX3Nvh7n38ZCSEjiUt5n7TdW5wuRynVQFQm6FOBji7Pw4H08guJyEjgcWCcMeaEy/QQ4GPgCWPMqpqVW/91mvQixfhwaMEDTpeilGogKhP0a4DuIhIhIgHAZGCp6wIiEgv8EyvkD7lMDwAWAzONMfPdV3b91SYsgvVdbyc29wc2fL3Q6XKUUg3AOYPeGFME3A18CmwB5hljNonIdBEZZy/2AtAUmC8iSSJS+kFwDTAMmGpPTxKRGPe/jPolbtLjpEo7mn37RwpO5DtdjlLKy4kxFXa3OyY+Pt4kJCQ4XUatS1oxh5jv7mBV9wcYdN1TTpejlKrnRGStMSa+onl6ZaxDYkZMZn3jgfTb/gaHD+xzuhyllBfToHdQi6teJIACfp7ze6dLUUp5MQ16B3XsHs3aDlMYcGw52xK+dLocpZSX0qB3WOSUP5NBc+STRygpLna6HKWUF9Kgd1jTkObsjXuEHkXbSVj6utPlKKW8kAa9B+g/5g62+vXmvPUvknXsiNPlKKW8jAa9BxAfH3zHvEBzk8Xm2Y85XY5Systo0HuI7jFDSWg5hv4H5rN3y1qny1FKeRENeg/SbfJz5EkgWR/qACVKKffRoPcgLdqEsbnn3USeWMe6z2c5XY5Sykto0HuY+KsfYo9PJ9qtmk5+7nGny1FKeQENeg/j5x/A8RHP0MEcYt3cPzldjlLKC2jQe6B+Q8aS2HQ4MXv+w4F9O5wuRylVz2nQe6j2E61ButLnPehwJUqp+k6D3kO179yTpM43E3f8G5K//5/T5Sil6jENeg8WO/lJ9tOaoBWPU1RY4HQ5Sql6SoPegwU2acqBwX8komQvaxe+5HQ5Sql6SoPew8VccgMbG8XSe+tr/JKx3+lylFL1kAa9hxMfH0KufIkmJo/ts3WAEqVU1WnQ1wOde/cnoe1EBhz5HzvXr3S6HKVUPaNBX0/0nvIMxySYoo8e1vvgKKWqRIO+nght3opdUQ/Rq3Azaz/6l9PlKKXqEQ36eqT/+LvZ4dedzonPcjzrF6fLUUrVExr09YiPry/Fo56jNb+wcfaTTpejlKonNOjrmV7xI1gTOor+6bNI2bnR6XKUUvWABn09FDHlBQoI4OhCvQ+OUurcNOjroVbtOpHc/U6i81az/ss5TpejlPJwGvT1VNzER9nnE0bL76ZxIj/X6XKUUh5Mg76eCmgUyLFhfyLc7Cdx3l+dLkcp5cE06OuxqIt+zbomFxC9659kpO9xuhyllIfSoK/n2lz9N3wpYe+ch5wuRSnloTTo67mwrr1JDL+e+KzP2br6M6fLUUp5IA16LxA95WkO0hK/zx6luKjI6XKUUh5Gg94LNGkaSuqAx+hWvIuExa86XY5SysNo0HuJuNG3sDkgkh6bXibzaIbT5SilPEilgl5ERonINhHZKSKPVjD/ARHZLCIbRGSFiHR2mfeJiBwTkY/cWbg6lfj40Gjsi4SY42ydfdqvSCnVgJ0z6EXEF3gdGA30AaaISJ9yi60D4o0xUcAC4HmXeS8AN7inXHU250UOIqH1BOIPLeTnTaudLkcp5SEq06IfCOw0xuw2xhQAc4DxrgsYY74yxpRenrkKCHeZtwLIdlO96hx6Tv4r2RJE7pKHdIASpRRQuaAPA1Jcnqfa087kVmB5VYoQkd+ISIKIJGRkaP9yTTRr1Y5tfe6jb8EGEj95z+lylFIeoDJBLxVMMxUuKHI9EI/VXVNpxph/GWPijTHxrVu3rsqqqgLxV93PLt8Iwn76M3k5+mVKqYauMkGfCnR0eR4OpJdfSERGAo8D44wxJ9xTnqoOXz8/TlzyLO04zPrZTzldjlLKYZUJ+jVAdxGJEJEAYDKw1HUBEYkF/okV8ofcX6aqqj6DRpEQPILYlJmk/7zV6XKUUg46Z9AbY4qAu4FPgS3APGPMJhGZLiLj7MVeAJoC80UkSUTKPghE5DtgPjBCRFJF5DK3vwpVoU6TX6IYHw4u0AFKlGrI/CqzkDFmGbCs3EmPzGAAABm1SURBVLQnXR6PPMu6Q6tdnaqRNmER/Nj1Ngb//Dobv11M5LAJTpeklHKAXhnr5WKveZxUaUfI13+ksEAPnSjVEGnQe7nAxkEcHjKNziUprJ3/nNPlKKUcoEHfAET/ahLrAwfQd/s/OHwg5dwrKKW8igZ9AyA+PjS/6kUaUcDuOb93uhylVB3ToG8gOvWIIbH9ZAYeW8b2xK+dLkcpVYc06BuQvlP+zGGawbKHKSkudrocpVQd0aBvQIJDW/Bz7CP0KNpOwtJ/OF2OUqqOaNA3MP3H3MFWv950Xf8iWceOOF2OUqoOaNA3MD6+vvhe8TwtTCabZz/udDlKqTqgQd8AdY8dRkKLK+h/YB6b1v/kdDlKqVqmQd9AdZvyPDnSmKYLr+PWv3/I7J/2cfxEkdNlKaVqgQZ9A9WiTRg+1y+kvX8ufzr2CK8u+pqBf/mC3y9Yz9q9v2BMhUMOKKXqIQ36Biyk2yACbl5Ce/9cvm79Itf39uOjDfv59Rs/cOnL3/Lv73ZzNKfA6TKVUjUkntZyi4+PNwkJCU6X0bCkrIH3J0DT1uRcu4T/7YY5a1JISjlGgK8Pl/Rty+QBHRlyXit8fCoacEwp5TQRWWuMia9wnga9AlzCvg1M/QhCOrD1QBZz16SwKDGNzLxCwps3ZlJ8R66OD6d9aGOnK1ZKudCgV5WT8pMd9m1h6scQ0h6A/MJiPt10gLlrUvhh1xF8BC7q2YZJAzryq15t8PfVHkClnKZBrypv32r44CoIbmeFfXC7U2bvPZLDvIQU5iekcij7BK2aNuLq/uFMGtCRiFZBDhWtlNKgV1WzbxW8fxWEdLC6ccqFPUBRcQlfb8tgzpoUvtp2iOISw6CuLZg8oBOj+rUj0N/XgcKVarg06FXV7f0RPvg1hIbBTR9BcNszLnowK58Fa1OZuyaFfUdzCQn0Y0JsGJMGdKJPh5A6LFqphkuDXlXP3h/gg6shNNxq2Tdtc9bFS0oMq3YfYc6aFD5JPkBBcQlR4aFMGtCRcdEdCA70r6PClWp4NOhV9e35HmZdDaEdKxX2pX7JKeDDpDTm/JTCtoPZNPb3ZUxUeyYP7Ehcp+aI6GmaSrmTBr2qmT0rYdZEaNbJ6sZp2rrSqxpjWJ+aydw1+1ialE5OQTHd2jRl8oCOTIgNo2XTRrVYuFINhwa9qrmfv7PCvnkXuOl/VQr7UjknivhoQzpz1qSwbt8x/H2FS/u0Y9KAjlzYTS/GUqomNOiVe/z8Lcy6BlpEWGEf1Kram9p2INu6GGtdKsdyCwlr1phJAzoyUS/GUqpaNOiV++z+Bv57DbQ4D25aWqOwBzhRVMxnmw4yd00KK3cexkdgeI/W/N+I7sR1au6mopXyfhr0yr12fw3/nQQtu8GNSyGopVs2u+9ILvPXpjBnTQpHcwq4f2R3fntRN3y1S0epczpb0Ou166rqul4EU+bAkZ0wczzkHnXLZju1bMKDl/ZkxYPDGd2vHS9+tp3r/r2KA5n5btm+Ug2VBr2qnvMuhsn/hcPb4b1xbgt7gJBAf16bEsvzV0exPiWTUa9+y+ebD7pt+0o1NBr0qvq6jYApdtjPdG/YiwjXxHfko3supENoY26fmcBTS5LJLyx22z6Uaig06FXNdBtptewztru1G6fUea2bsvh3F3DLkAje+3EvV77+PTsOZrt1H5V2PAMK85zZt1I1oEGvaq57adhvhfevhLxf3Lr5Rn6+PDm2D+9MHUBG9gnGzljJ7J/21d1wh/s3wPyp8FIPeC0edn1ZN/tVyk006JV7dB8Jk2bBoS0w0/1hD3BxrzYsv3co8Z1b8IdFG/ndfxPJzC10+37KlN7r559DYecKOP+3ENDEumf//+6FEw59s1CqivT0SuVe2z+FuddD275ww4fQuJnbd1FSYvjXd7t58dNttA0J5NXJMcR3aeGejRsDO7+A716CfT9Ck1Yw+C4YcBsEhlpdN189Az+8Zt3/Z/xr1llISjlMz6NXdWvbJ1bYt4uEGxbXStgDJKUc457Z60j9JZd7R/Tg7l/V4Jz7kmLYvARW/g0ObISQcBhyL8Reb7Xiy9u3GpbcZZ1iOuA2GPk0NGpasxekVA1o0Ku6t205zL0B2kdZYR8YWiu7yc4v5IkPk1mSlM7AiBa8MimGDs2qcAuFogLYMAdWvgJHd0HL7nDh/RA5EfwCzr5uYR58+Wf48XXrhm/jX4eIoTV7QUpVU40vmBKRUSKyTUR2isijFcx/QEQ2i8gGEVkhIp1d5t0kIjvsn5uq/zJUvdJzNFwz0zqQ+f5VkJ9ZK7sJDvTnlUkxvDQxmuS0TEa/+h2fJB8494oFOfDjP+DVaFj6f9Ao2Kr3d6sh9rpzhzyAf2O47C9w83Lw8YX3xsCyh61tK+VBztmiFxFfYDtwCZAKrAGmGGM2uyxzMbDaGJMrIr8FLjLGTBKRFkACEA8YYC3Q3xhzxiN12qL3Mls/hnk3QodYuH4RBNbeiFM/H87h/2YnkpyWxfWDOvHEFX1OH9Iw7xf46S1Y9QbkHYXOF8LQB+C8X0FN7pFfkAsrpsPqN6w7fI7/B3QZUqPXo1RV1LRFPxDYaYzZbYwpAOYA410XMMZ8ZYzJtZ+uAsLtx5cBnxtjjtrh/jkwqjovQtVTva6Aie9C+jpraML8rFrbVUSrIBb9dgi3D43gg1X7GDdjJdsO2GfGZB+Az/4IL/eDr/4CHQfCLZ/BzR9bF37VdCCUgCYw+llrQHWAd6+A5Y9aHwBKOawyQR8GpLg8T7WnncmtwPKqrCsivxGRBBFJyMjIqERJql7pPRaufgfSE63RqmrxtMQAPx8ev6IP790ykKM5Bdw1YyHb374N80oU/DgDeoyCO7+Ha+dCp/PdX0CXC+G3P8DA263W/ZtDrPF3lXJQZYK+oqZOhf09InI9VjfNC1VZ1xjzL2NMvDEmvnXrqg9ooeqBPuPg6v9AaoJ1bnotn4M+PDSDld1n85nf/XTet5jvgkaSdduPcPXb0K5fre6bgCC4/AXrnv0lRfDOaPj0cb2qVjmmMkGfCnR0eR4OpJdfSERGAo8D44wxJ6qyrmog+oy3w36NNVpVbYR9yhqYPQXeGEzgzk/wGXQXCy78mFuPXM9lM9NYvfuI+/d5JhHD4Lc/Qvwt1reJNy+ElJ/qbv9OytoP379qHQvJ1hvSOa0yB2P9sA7GjgDSsA7GXmuM2eSyTCywABhljNnhMr0F1gHYOHtSItbB2DPeEEUPxjYAmxbDglutfvLrFtT8/HNjrHvkf/cS7PkOApvBoN/CwN9AE+tCqg2p1jn3+47m8n+/6s7//aobfr51eGH47q9hyd2QlQaD74aLHwf/wLrbf10oLoIdn0HiTOtfY9+ATnytu51GTbaO2VR0XYKqsRqfRy8ilwOvAL7Af4wxfxGR6UCCMWapiHwBRAL77VX2GWPG2eveAjxmT/+LMeads+1Lg76BSF4EC2+DjufDdfOrF/YlJbDtYyvg09dB03Zwwd3Qf6p1umQ5x08U8eSSZBYlpjGgS3NemRxLWFXOua+p/Cz4/I+w9l1o1QOufAPCK/x/Wb8c3Q3rPoB1s+D4AWjaFmKusy42Ky6EDXNhwzzISoWAptB7HERPgi5DrdNSlXX68c4vrOs6YqZUaxN6wZTyTMkLrbDvNNgK+4Cgyq1XXAgbF8DKl+HwNut0xiH3Qcy14NfonKsvXpfKE4uT8fURnvt1FKMj29fsdVTVzhWw9B7ITreuvr3oD5Wq26MU5sPWjyDxPWssYfGB7pdC3I3Wv77+py5fUgJ7v7cuTtu0BAqyIbgDRE20Wvpt+zjzOpyUmWpdWLj1Y9izEkoKoX0M3PFNtTanQa8818YFsOh26DzEOhPmbGFfmGe1HL//O2TugzZ9rXPg+1wJvn5V2u3eIzncM3sd61MzmTKwE0+O6UPjgDpsXeZnWgdo170PrXvBlf+AsP51t//qOrjJ6ppZPwfyj0GzzhB3g9WCD+lQuW0U5sG2ZbB+rtWKNcXW7TKiJltXJAe3rd3X4BRjrNtrbFtmhfuBDdb0lt2g5+VWt1b4gGp/y9GgV55tw3xY/Bs77Oed3oebnwlr3oZV/4CcDAgfCEMfhB6X1ej894KiEl76fBv//GY33ds05e9TYundvvYu6KrQjs+t1v3xg3DhfTD8Ec9r3Z/Itr59Jc6EtLXgG2CdMht3I3QZBj41ONZxPMPa9oY5Vveb+EDXiyG6tD+/kt/yPFVRgfVNZtsyq/WemQKIdXyqNNxbdXfLrjTolefbMA8W32Gdhz5lrhX2xzOsc9F/+jecyLSuXh36oPWBUNMLnFx8tyOD++euJyu/kCeu6M0Ngzojbtz+OeUdg08fg6RZ0KaP1XffIabu9l8RY6xTYRPfs46nFOZA697Q/yaImlR2kNutMrZbgb9hnhWIAU2tD5SoSdYZTPWlPz/vmPVNZdsy2PGF9bfr19g6IN3zcutajqbuP41cg17VD+vnWmEfMQza9Ia170FRvvWffegD1m0Uasnh4yd4aP56vt6WwSV92vL8r6NoHlSJ+9240/ZPrdZ9Tob1gTbs4crdc8edco5YB08TZ0LGFvAPgn5XQdxN1oHjuvgALCmBfT9Y3UObl8CJLAhub3XrRE+2boHtaY7ts1rs25bZ/e1F1i2ue46CnldYt7Ku5bONNOhV/bF+Diy+02q9RU2yDrK27lEnuy4pMbzzwx6eXb6FlkGNeHlSDIPPa1kn+y6T9wt88gdYPxva9rNa9+2janefJSXw8zdWuG/9CIoLICze6prpd1WFZzCdiTGGguISCoqsn+BAfwL8atC1U5hnBegGuz+/pAjaRlpn7UROhOB21d92TRgD+9fbXTLLrL53sM6m6nm59RMeX6ffQjToVf2SthaC2kCzjudethYkp2Vyz+x1/Hwkh7sv7sa9I7rX7Tn3AFuXwUf3Qe4Rq2U/9MHTz2SxFZcY8guLOVF0MmALik8+P3X6ycc+Ofvpsm8xPdI/JCQ/nTy/EDa0GMWaFmNI9Y84df3iEgqKisu2caLw1G0VFJVwwn7uyt9X6NkumH4dQukbFkq/DiH0bh9y+s3mKiPnsNWfv36OdTsN8bFayqXn59f2eABFBdZ1GqX97VlpVg0dzz8Z7q261W4NZ6FBr1QV5ZwoYtrSTcxfm0r/zs15ZVIMHVu496t3cYkhp6CI4/lFZOcXcfxEIdllj4sozD7MgC3P0vvwp6QGduedVr9nG53JPlFEdn4hx+3lcguKK71PP4q42CeJSb5fcbFPEr5i+L64L3OKL2YFA8AvkAA/HwJ8fax/7ceN/H1pVG5a6eNGfi6Pyy2zPyufTWlZJKdncswe9tHXR+jepil9O4TSLyyEfmGh9G4fQtNGVThz6vAO+/z8uVa3iX8Q9B5jfQvsepH7WtJ5x6wD5ts+tvrbC7LBv4l1vKjn5dYJAUGt3LOvGtKgV6qaliSl8cTiZBB49qoorohqT0mJIbewuCxsreAtsoP31LDOzi+0/z05rTSgj58oOuf+RWBcQCJPyVsEk8P8oCl83uJamgQGEhzoR9NGfjQN9KOxv69L8PqeDGh7WnDuPtrunE/LnQvwyz1EcVBb8vtNpiTqevxan0eAn0/1R+eqBGMMacfySE7LYlN6JslpmWxMy+Lw8RNlrzOiVRD9SsO/Qyh9O4QS2qTibzFlSkogZZXVyt/0oXXgs2k7iLza6s9vF1n1Yn/Za/e3f2yNG1xSZH3DLOtvH26NReBhNOiVqoF9R3K5Z846klKOEdzIj+MFRVTmv01QgC/Bgf40tQM5ONCvLJyDA/3LppU9tx+HBPqVPQ4K8MPHR6yDpMsftrou2sdYfffnusioMB+2LLX63vd8Z92KoMdlVt97t0uqfO1BbTiUlU9yeibJaVkkp2WyKT2LtGMnb/7WsUVjO/xD6dvBav23anqG008L82H7J1Yrf8dnVkC36XuyP/9M5/kbA/uTrO6ybcvgYLI1vVVP6HW5Fe5h/Wt2Gmkd0KBXqoYKi0t474c9pB3LI7hcMJ8McH/r30AroGulhbx5CXz0gHUmykWPwgX3nh7YB5KtcN8w17qoqXkXK9yjr4WQOr4KuBqO5hTYrf4s+0Mgk71HTt7Xv11IIP3CQuyun1Aiw0JpG9Lo1FNic47ApkVWSz8tARCrJR412TqLy9ff+vDbave3Z6fb/e2D7HC/HFqeV/cvvgY06JXyJjmH4eMHYfOH0CHOat2HdDh5UVN6on1R0zj7oqahHt8aPZfMvEI2p5/s9klOz2JXxvGyb1atmgac7PO3PwDCmze2wv/wTpf+/L1WH7v4ntrf3usK6H4ZBNXxWVZupEGvlDdKXmQFfsFx8PGDwlzrgqu4myDqmtq5qMmD5BYUsWV/Vlm3T3J6FjsOZlNUYmVaSKAf/cJcun06hBCRuxGf5AVgSqxxjSOGe81dRDXolfJWxw/Bl3+2jmbG3ghhcXVzUZOHyi8sZvvB7LJun01pmWw5kF122mdQgC99OoQwqGtLrowN47zWtXxKZh3SoFdKNViFxSXsPHS87GDvhtRjJKUco8RAdHgoE2LDGBvdgZZnOshbT2jQK6WUi0NZ+SxJSmfRujS27M/Cz0cY3qM1E+LCGNm7bfUu6HKYBr1SSp3B1gNZLE5M48OkNA5mnSC4kR+XR7ZnQlwYA7u0sE5vrQc06JVS6hyKSww/7jrC4nVpfJK8n5yCYsKaNebK2A5MiA2nWxvP7s/XoFdKqSrILSji880HWZSYxnc7MigxEOXSn3/Gi7YcpEGvlFLVdCg7n6VJ6SxKTGPz/ix8S/vzY8O4pI/n9Odr0CullBtsO5DNonWpLFmXzoGsfIIb+TE6sh0TYsM5P8LZ/nwNeqWUcqPiEsPq3UdYtC6N5RtP9uePj+nAVXFhdGtT+Xv4u4sGvVJK1ZK8gmI+23yAxevS+G7HYYpLDJFhVn/+uJi668/XoFdKqTqQkX2CpevTWbwuleQ0qz9/WPdWTIgL55LebWkcUHv9+Rr0SilVx3YczGbRujSWrEsjPTOfpo38GN2vHRPiwhgU0dLt/fka9Eop5ZCSEsOqn4+wODGN5ckHOH6iiA6hgYyPDeOq2DC6t3VPf74GvVJKeYC8gmI+33KQxYmpfGv35/cLC2FCbDjjojvQOrj6/fka9Eop5WEysk/wv/XpLF6Xxsa0THx9hNH92jHj2rhqbe9sQe/8WGJKKdUAtQ5uxC0XRnDLhRHsPJTNosS0WrvDtAa9Uko5rFubYH4/qletbb9+jy+mlFLqnDTolVLKy2nQK6WUl9OgV0opL6dBr5RSXk6DXimlvJwGvVJKeTkNeqWU8nIedwsEEckA9tZgE62Aw24qx520rqrRuqpG66oab6yrszGmdUUzPC7oa0pEEs50vwcnaV1Vo3VVjdZVNQ2tLu26UUopL6dBr5RSXs4bg/5fThdwBlpX1WhdVaN1VU2Dqsvr+uiVUkqdyhtb9EoppVxo0CullJfzmqAXkf+IyCERSXa6llIi0lFEvhKRLSKySUTudbomABEJFJGfRGS9XdfTTtfkSkR8RWSdiHzkdC2lRGSPiGwUkSQR8ZixLkWkmYgsEJGt9t/ZYKdrAhCRnvZ7VfqTJSL3eUBd99t/88kiMltEAp2uCUBE7rVr2lQb75PX9NGLyDDgODDTGNPP6XoARKQ90N4YkygiwcBa4EpjzGaH6xIgyBhzXET8gZXAvcaYVU7WVUpEHgDigRBjzBin6wEr6IF4Y4xHXWQjIu8B3xlj/i0iAUATY8wxp+tyJSK+QBpwvjGmJhdD1rSOMKy/9T7GmDwRmQcsM8a861RNdl39gDnAQKAA+AT4rTFmh7v24TUtemPMt8BRp+twZYzZb4xJtB9nA1uAMGerAmM5bj/1t3884hNfRMKBK4B/O12LpxOREGAY8DaAMabA00LeNgLY5WTIu/ADGouIH9AESHe4HoDewCpjTK4xpgj4Bpjgzh14TdB7OhHpAsQCq52txGJ3jyQBh4DPjTEeURfwCvB7oMTpQsoxwGcislZEfuN0MbauQAbwjt3V9W8RCXK6qApMBmY7XYQxJg14EdgH7AcyjTGfOVsVAMnAMBFpKSJNgMuBju7cgQZ9HRCRpsBC4D5jTJbT9QAYY4qNMTFAODDQ/vroKBEZAxwyxqx1upYKDDHGxAGjgd/ZXYVO8wPigDeMMbFADvCosyWdyu5OGgfM94BamgPjgQigAxAkItc7WxUYY7YAzwGfY3XbrAeK3LkPDfpaZveBLwRmGWMWOV1PefZX/a+BUQ6XAjAEGGf3h88BfiUiHzhbksUYk27/ewhYjNWf6rRUINXl29gCrOD3JKOBRGPMQacLAUYCPxtjMowxhcAi4AKHawLAGPO2MSbOGDMMqwvabf3zoEFfq+yDnm8DW4wxf3O6nlIi0lpEmtmPG2P9B9jqbFVgjPmDMSbcGNMF6+v+l8YYx1tcIhJkH0zH7hq5FOvrtqOMMQeAFBHpaU8aATh6oL8CU/CAbhvbPmCQiDSx/2+OwDpu5jgRaWP/2wm4Cje/Z37u3JiTRGQ2cBHQSkRSgaeMMW87WxVDgBuAjXZ/OMBjxphlDtYE0B54zz4bwgeYZ4zxmFMZPVBbYLGVDfgB/zXGfOJsSWX+D5hld5HsBm52uJ4ydn/zJcAdTtcCYIxZLSILgESsrpF1eM6tEBaKSEugEPidMeYXd27ca06vVEopVTHtulFKKS+nQa+UUl5Og14ppbycBr1SSnk5DXqllPJyGvRKKeXlNOiVUsrL/T+Da82caGXdMQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def error(y_pred, y):\n",
    "    return 1 - calc_acc(y_pred, y)\n",
    "\n",
    "X_train_s, X_val_s, y_train_s, y_val_s = tts(spam_X, spam_y, test_size=0.8, random_state=27)\n",
    "errors_tree = []\n",
    "errors_forest = []\n",
    "tree = DecisionTree(spam_features, spam_classes)\n",
    "forest = RandomForest(spam_features, spam_classes, 4)\n",
    "\n",
    "for i in range(1,10):\n",
    "    tree.fit(X_train_s, y_train_s,i)\n",
    "    forest.fit(X_train_s, y_train_s, i)\n",
    "    errors_tree.append(error(tree.predict(X_val_s), y_val_s))\n",
    "    errors_forest.append(error(forest.predict(X_val_s), y_val_s))\n",
    "    \n",
    "plt.plot(list(range(1,10)), errors_tree, label=\"Decision Tree\")\n",
    "plt.plot(list(range(1,10)), errors_forest, label=\"Random Forest\")\n",
    "plt.legend()\n",
    "plt.title(\"Validation Error on Spam Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex, 1.0\n",
      "\t\tpclass, 3.0\n",
      "\t\t\t\tfare, 23.45\n",
      "\t\t\t\t\t\t{'Died': 0.42142857142857143, 'Survived': 0.5785714285714286}\n",
      "\t\t\t\t\t\t{'Died': 0.9, 'Survived': 0.1}\n",
      "\t\t\t\tembarked, 3.0\n",
      "\t\t\t\t\t\t{'Died': 0.08, 'Survived': 0.92}\n",
      "\t\t\t\t\t\t{'Died': 0.0, 'Survived': 1.0}\n",
      "\t\tcabin, 6.0\n",
      "\t\t\t\tage, 4.0\n",
      "\t\t\t\t\t\t{'Died': 0.35714285714285715, 'Survived': 0.6428571428571429}\n",
      "\t\t\t\t\t\t{'Died': 0.8651252408477842, 'Survived': 0.1348747591522158}\n",
      "\t\t\t\tage, 18.0\n",
      "\t\t\t\t\t\t{'Died': 0.0, 'Survived': 1.0}\n",
      "\t\t\t\t\t\t{'Died': 0.6605504587155964, 'Survived': 0.3394495412844037}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample visualization of Decision Tree structure\n",
    "titanic = DecisionTree(titanic_features, titanic_classes)\n",
    "titanic.fit(titanic_X, titanic_y, 3)\n",
    "print(titanic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will generate our predictions on a test set, and write them to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write our results to CSV file\n",
    "def results_to_csv(y_test, name):\n",
    "    y_test = y_test.astype(int)\n",
    "    df = pd.DataFrame({'Category': y_test})\n",
    "    df.index += 1 # Ensures that the index starts at 1. \n",
    "    csv_name = name + '.csv'\n",
    "    df.to_csv(csv_name, index_label='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit decision tree and random forest to both datasets, then generate predictions\n",
    "tree_t = DecisionTree(titanic_features, titanic_classes)\n",
    "tree_s = DecisionTree(spam_features, spam_classes)\n",
    "forest_t = RandomForest(titanic_features, titanic_classes, 10)\n",
    "forest_s = RandomForest(spam_features, spam_classes, 10)\n",
    "tree_t.fit(titanic_X,titanic_y, 10)\n",
    "tree_s.fit(spam_X,spam_y, 3)\n",
    "forest_t.fit(titanic_X, titanic_y, 3)\n",
    "forest_s.fit(spam_X, spam_y,3)\n",
    "titanic_test_tree = tree_t.predict(titanic_test)\n",
    "spam_test_tree = tree_s.predict(spam_test)\n",
    "titanic_test_forest = forest_t.predict(titanic_test)\n",
    "spam_test_forest = forest_s.predict(spam_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a CSV file for each set of predictions\n",
    "results_to_csv(titanic_test_tree, \"titanic_tree\")\n",
    "results_to_csv(spam_test_tree, \"spam_tree\")\n",
    "results_to_csv(spam_test_forest, \"spam_forest\")\n",
    "results_to_csv(titanic_test_forest, \"titanic_forest\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
