{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is an implementation of a decision tree and random forest for classification on the Titanic and Spam datasets. The decision tree calculates a split that maximizes information gain, and builds a tree structure maintaining class probabilities. Traversal stops when a class reaches a probability of 1.0, or we reach a specified maximum depth. The random forest implements the bagging ensemble method, training individual trees on random subsets of the data, then outputting the mode of all predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import genfromtxt\n",
    "import scipy.io\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "%matplotlib inline\n",
    "\n",
    "class Node:\n",
    "    \"\"\"\n",
    "    A single node in the decision tree:\n",
    "    \n",
    "    left: pointer to left subtree\n",
    "    right: pointer to right subtree\n",
    "    split_rule: A pair containing a feature and threshold to split on (f, t).\n",
    "    depth: The current depth of the node in the tree\n",
    "    probs: Probability of each class label at this node\n",
    "    \"\"\"\n",
    "    def __init__(self, left, right, rule, depth, probs = None):\n",
    "        self.split_rule = rule\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.depth = depth\n",
    "        self.probs = probs\n",
    "    \n",
    "class DecisionTree:\n",
    "    \n",
    "    def __init__(self, features, classes):\n",
    "        self.classes = classes\n",
    "        self.class_indices = np.arange(len(classes))\n",
    "        self.features = features\n",
    "    def calc_probs(self, y):\n",
    "        return np.array([np.mean([y == label * np.ones(len(y))]) for label in self.class_indices])\n",
    "        \n",
    "    def entropy(self, y):\n",
    "        \"\"\"\n",
    "        Calculates the entropy given all the labels\n",
    "        \"\"\"\n",
    "        #probs = np.array([np.mean([int(y_i == label) for y_i in y]) for label in self.class_indices])\n",
    "        return stats.entropy(self.calc_probs(y))\n",
    "\n",
    "    def information_gain(self, X, y, idx, thresh):\n",
    "        \"\"\"\n",
    "        Calculates information gain given a vector of features and a split threshold\n",
    "        \"\"\"\n",
    "        left, right = self.split(X, y, idx, thresh)\n",
    "        left_H = self.entropy(y[left]) if list(left) else 0\n",
    "        right_H = self.entropy(y[right]) if list(right) else 0\n",
    "        H_after = (len(left) * left_H + len(right) * right_H) / len(y)\n",
    "        return self.entropy(y) - H_after\n",
    "\n",
    "    def split(self, X, y, idx, thresh):\n",
    "        \"\"\"\n",
    "        Returns a split of the dataset given an index of the feature and\n",
    "        a threshold for it\n",
    "        \n",
    "        \"\"\"\n",
    "        left, right = [], []\n",
    "        f = self.features[idx]\n",
    "        for i in range(len(X)):\n",
    "            point = X[i]\n",
    "            comparison = lambda x,y : (x == y if f in [\"pclass\", \"sex\", \"embarked\"] else x < y)\n",
    "            if comparison(point[idx], thresh):\n",
    "                left.append(i)\n",
    "            else:\n",
    "                right.append(i)\n",
    "        return np.array(left), np.array(right)\n",
    "        \n",
    "    def segmenter(self, X, y):\n",
    "        \"\"\"\n",
    "        Compute entropy gain for all single-dimension splits,\n",
    "        return the feature and the threshold for the split that\n",
    "        has maximum gain\n",
    "        \"\"\"\n",
    "        best_gain = -float('inf')\n",
    "        best_pair = None\n",
    "        for i in range(len(self.features)):\n",
    "            thresholds = list(set(X[:,i]))\n",
    "            for threshold in thresholds:\n",
    "                curr_gain = self.information_gain(X, y, i, threshold)\n",
    "                if curr_gain > best_gain:\n",
    "                    best_pair = (i, threshold)\n",
    "                    best_gain = curr_gain\n",
    "        return best_pair\n",
    "             \n",
    "    def fit(self, X, y, max_depth):\n",
    "        \"\"\"\n",
    "        Fit the model to a training set.\n",
    "        \"\"\"\n",
    "        self.root = self.grow_tree(X, y, 0, max_depth)\n",
    "        \n",
    "    def grow_tree(self, X, y, curr_depth, max_depth):\n",
    "        probs = self.calc_probs(y)\n",
    "        feature, threshold = self.segmenter(X, y)\n",
    "        left, right = self.split(X, y, feature, threshold)\n",
    "        X_left = None if not list(left) else X[left]\n",
    "        y_left = None if not list(left) else y[left]\n",
    "        X_right = None if not list(right) else X[right]\n",
    "        y_right = None if not list(right) else y[right]\n",
    "        if 1.0 in probs or curr_depth == max_depth:\n",
    "            return Node(None, None, None, curr_depth, probs)\n",
    "        if X_left is not None:\n",
    "            left_node = self.grow_tree(X_left, y_left, curr_depth + 1, max_depth)\n",
    "        else:\n",
    "            left_node = Node(None, None, None, curr_depth + 1, probs)\n",
    "        if X_right is not None:\n",
    "            right_node = self.grow_tree(X_right, y_right, curr_depth + 1, max_depth)\n",
    "        else:\n",
    "            right_node = Node(None, None, None, curr_depth + 1, probs)\n",
    "        return Node(left_node, right_node, (feature, threshold), curr_depth)\n",
    "   \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the labels for input data \n",
    "        \"\"\"\n",
    "        y = []\n",
    "        for point in X:\n",
    "            node = self.root\n",
    "            while node is not None and node.probs is None:\n",
    "                feature, threshold = node.split_rule\n",
    "                comparison = lambda x,y : (x == y if self.features[feature] in [\"pclass\", \"sex\", \"embarked\"] else x < y)\n",
    "                node = node.left if comparison(point[feature], threshold) else node.right\n",
    "            y.append(np.argmax(node.probs))\n",
    "        return np.array(y)\n",
    "                    \n",
    "    \"\"\"\n",
    "    Visualization method for the tree\n",
    "    \"\"\"    \n",
    "    def generateString(self, node):\n",
    "        if not node:\n",
    "            return \"\"\n",
    "        if node.probs is not None:\n",
    "            output = \"(\"\n",
    "            for i in range(len(node.probs)):\n",
    "                output += f\"{self.classes[i]} : {node.probs[i]}, \"\n",
    "            output = output[:-2] + \")\\n\"\n",
    "            return \"\\t\" * node.depth + output\n",
    "        fidx, thresh = node.split_rule\n",
    "        return \"\\t\" * node.depth + f\"{self.features[fidx]}, {thresh}\\n\" \\\n",
    "             + \"\\t\" * node.left.depth \\\n",
    "             + self.generateString(node.left) \\\n",
    "             + \"\\t\" * node.right.depth \\\n",
    "             + self.generateString(node.right)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        \n",
    "        return self.generateString(self.root)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    \n",
    "    def __init__(self, features, classes, num_trees):\n",
    "        \"\"\"\n",
    "        Initialization of a random forest\n",
    "        \"\"\"\n",
    "        self.trees = np.array([DecisionTree(features, classes) for _ in range(num_trees)])\n",
    "    def fit(self, X, y, max_depth):\n",
    "        \"\"\"\n",
    "        Fit the model to a training set\n",
    "        \"\"\"\n",
    "        for tree in self.trees:\n",
    "            X_t, y_t = [], []\n",
    "            for _ in range(len(y)):\n",
    "                idx = np.random.randint(len(y))\n",
    "                X_t.append(X[idx])\n",
    "                y_t.append(y[idx])\n",
    "            \n",
    "            tree.fit(np.array(X_t), np.array(y_t), max_depth)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the labels for input data \n",
    "        \"\"\"\n",
    "        predictions = np.array([tree.predict(X) for tree in self.trees])\n",
    "        final_predictions = np.array([stats.mode(predictions[:, i])[0][0] for i in range(len(predictions[0]))])\n",
    "        return final_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perfomance Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will preprocess the data to encode categorical values and fill in missing values. Then, we will train our models and measure their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nprasad/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:34: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "/Users/nprasad/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:35: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n"
     ]
    }
   ],
   "source": [
    "# Check if s is a numerical value\n",
    "def is_numeric(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except (ValueError, TypeError):\n",
    "        return False\n",
    "# Preprocess the data by converting from strings to floats, and encoding categorical data with the LabelEncoder      \n",
    "def process_data(features, dataset):\n",
    "    for i in range(len(features)):\n",
    "            column = dataset[:,i]\n",
    "            for j in range(len(column)):\n",
    "                if column[j] == '':\n",
    "                    values = np.array([x for x in column if x != ''])\n",
    "                    if all(list(map(is_numeric, values))):\n",
    "                        values = values.astype(np.float64)\n",
    "                        column[j] = np.mean(values)\n",
    "            dataset[:,i] = column\n",
    "            # Label encoding for categorical features\n",
    "            le = LabelEncoder()\n",
    "            if not is_numeric(dataset[0,i]):\n",
    "                le.fit(dataset[:,i])\n",
    "                dataset[:,i] = le.transform(dataset[:,i])\n",
    "    \n",
    "    return dataset.astype(np.float64)\n",
    "\n",
    "\"\"\"\n",
    "Read in the datasets from given files and run preprocessing.\n",
    "\"\"\"\n",
    "def generate_data(dataset):\n",
    "    # The titanic dataset requires preprocessing to convert categorical data and fill in missing values\n",
    "    if dataset == \"titanic\":\n",
    "    # Load titanic data       \n",
    "        data = genfromtxt('titanic_training.csv', delimiter=',', dtype=None)\n",
    "        test_data = genfromtxt('titanic_testing_data.csv', delimiter=',', dtype=None)\n",
    "        y = data[1:, 0]\n",
    "        class_names = [\"Died\", \"Survived\"]\n",
    "        features = data[0].astype(np.str)\n",
    "        data = process_data(features, data[1:].astype(np.str))\n",
    "        test_features = test_data[0].astype(np.str)\n",
    "        test_data = process_data(test_features, test_data[1:].astype(np.str))\n",
    "        y = y.astype(np.str)\n",
    "        empty_indices = [i for i in range(len(y)) if y[i] == '']\n",
    "        # Remove the indices with empty data\n",
    "        for i in empty_indices:\n",
    "            data = np.delete(data,i,0)\n",
    "            y = np.delete(y,i)\n",
    "        y = y.astype(np.int)\n",
    "    # The spam dataset does not require the above preprocessing: simply load the data    \n",
    "    elif dataset == \"spam\":\n",
    "        features = [\n",
    "        \"pain\", \"private\", \"bank\", \"money\", \"drug\", \"spam\", \"prescription\",\n",
    "        \"creative\", \"height\", \"featured\", \"differ\", \"width\", \"other\",\n",
    "        \"energy\", \"business\", \"message\", \"volumes\", \"revision\", \"path\",\n",
    "        \"meter\", \"memo\", \"planning\", \"pleased\", \"record\", \"out\",\n",
    "        \"semicolon\", \"dollar\", \"sharp\", \"exclamation\", \"parenthesis\",\n",
    "        \"square_bracket\", \"ampersand\"\n",
    "        ]\n",
    "        assert len(features) == 32\n",
    "\n",
    "    # Load spam data\n",
    "        data = scipy.io.loadmat('spam_data.mat')\n",
    "        X = data['training_data']\n",
    "        y = np.squeeze(data['training_labels'])\n",
    "        test_data = data['test_data']\n",
    "        class_names = [\"Ham\", \"Spam\"]\n",
    "        data = X\n",
    "    return data, y, test_data, features, class_names\n",
    "         \n",
    "    \n",
    "\n",
    "titanic_X, titanic_y, titanic_test, titanic_features, titanic_classes = generate_data(\"titanic\")\n",
    "spam_X, spam_y, spam_test, spam_features, spam_classes = generate_data(\"spam\")\n",
    "titanic_X = np.delete(titanic_X,0,1)\n",
    "titanic_features = titanic_features[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we measure the performance of both models through training and validation accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and validate both models, outputting training and validation accuracies\n",
    "X_train_t, X_val_t, y_train_t, y_val_t = tts(titanic_X, titanic_y, test_size=0.8, random_state=42)\n",
    "X_train_s, X_val_s, y_train_s, y_val_s = tts(spam_X, spam_y, test_size=0.8, random_state=42)\n",
    "titanic_tree = DecisionTree(titanic_features, titanic_classes)\n",
    "titanic_forest = RandomForest(titanic_features, titanic_classes, 5)\n",
    "spam_tree = DecisionTree(spam_features, spam_classes)\n",
    "spam_forest = RandomForest(spam_features, spam_classes, 5)\n",
    "titanic_tree.fit(X_train_t, y_train_t, 10)\n",
    "titanic_forest.fit(X_train_t, y_train_t, 10)\n",
    "spam_tree.fit(X_train_s, y_train_s, 10)\n",
    "spam_forest.fit(X_train_s, y_train_t, 10)\n",
    "titanic_tree_pred_tr = titanic_tree.predict(X_train_t)\n",
    "titanic_tree_pred_va = titanic_tree.predict(X_val_t)\n",
    "spam_tree_pred_tr = spam_tree.predict(X_train_s)\n",
    "spam_tree_pred_va = spam_tree.predict(X_val_s)\n",
    "titanic_forest_pred_tr = titanic_forest.predict(X_train_t)\n",
    "titanic_forest_pred_va = titanic_forest.predict(X_val_t)\n",
    "spam_tree_forest_tr = spam_forest.predict(X_train_s)\n",
    "spam_tree_forest_va = spam_forest.predict(X_val_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy for Titanic with Decision Tree: 0.9547738693467337\n",
      "Validation accuracy for Titanic with Decision Tree: 0.74\n",
      "Training accuracy for Titanic with Random Forest: 0.9698492462311558\n",
      "Validation accuracy for Titanic with Random Forest: 0.73375\n",
      "Training accuracy for Spam with Decision Tree: 0.8558994197292069\n",
      "Validation accuracy for Spam with Decision Tree: 0.7982116964717255\n",
      "Training accuracy for Spam with Random Forest: 0.6392649903288201\n",
      "Validation accuracy for Spam with Random Forest: 0.6295311744804253\n"
     ]
    }
   ],
   "source": [
    "def calc_acc(pred, actual):\n",
    "    \n",
    "    return np.mean(pred == actual)\n",
    "\n",
    "training_acc_titanic_tree = calc_acc(titanic_tree_pred_tr, y_train_t)\n",
    "validation_acc_titanic_tree = calc_acc(titanic_tree_pred_va, y_val_t)\n",
    "training_acc_titanic_forest = calc_acc(titanic_forest_pred_tr, y_train_t)\n",
    "validation_acc_titanic_forest = calc_acc(titanic_forest_pred_va, y_val_t)\n",
    "training_acc_spam_tree = calc_acc(spam_tree_pred_tr, y_train_s)\n",
    "validation_acc_spam_tree = calc_acc(spam_tree_pred_va, y_val_s)\n",
    "training_acc_spam_forest = calc_acc(spam_tree_forest_tr, y_train_s)\n",
    "validation_acc_spam_forest = calc_acc(spam_tree_forest_va, y_val_s)\n",
    "print(f\"Training accuracy for Titanic with Decision Tree: {training_acc_titanic_tree}\")\n",
    "print(f\"Validation accuracy for Titanic with Decision Tree: {validation_acc_titanic_tree}\")\n",
    "print(f\"Training accuracy for Titanic with Random Forest: {training_acc_titanic_forest}\")\n",
    "print(f\"Validation accuracy for Titanic with Random Forest: {validation_acc_titanic_forest}\")\n",
    "print(f\"Training accuracy for Spam with Decision Tree: {training_acc_spam_tree}\")\n",
    "print(f\"Validation accuracy for Spam with Decision Tree: {validation_acc_spam_tree}\")\n",
    "print(f\"Training accuracy for Spam with Random Forest: {training_acc_spam_forest}\")\n",
    "print(f\"Validation accuracy for Spam with Random Forest: {validation_acc_spam_forest}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we plot the validation error as a function of tree depth for both the decision tree and random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation Error on Spam Dataset')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def error(y_pred, y):\n",
    "    return 1 - calc_acc(y_pred, y)\n",
    "\n",
    "X_train_s, X_val_s, y_train_s, y_val_s = tts(spam_X, spam_y, test_size=0.8, random_state=27)\n",
    "errors_tree = []\n",
    "errors_forest = []\n",
    "tree = DecisionTree(spam_features, spam_classes)\n",
    "forest = RandomForest(spam_features, spam_classes, 4)\n",
    "\n",
    "for i in range(1,10):\n",
    "    tree.fit(X_train_s, y_train_s,i)\n",
    "    forest.fit(X_train_s, y_train_s, i)\n",
    "    errors_tree.append(error(tree.predict(X_val_s), y_val_s))\n",
    "    errors_forest.append(error(forest.predict(X_val_s), y_val_s))\n",
    "    \n",
    "plt.plot(list(range(1,10)), errors_tree, label=\"Decision Tree\")\n",
    "plt.plot(list(range(1,10)), errors_forest, label=\"Random Forest\")\n",
    "plt.legend()\n",
    "plt.title(\"Validation Error on Spam Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex, 1.0\n",
      "\t\tpclass, 3.0\n",
      "\t\t\t\tfare, 23.45\n",
      "\t\t\t\t\t\t(Died : 0.42142857142857143, Survived : 0.5785714285714286)\n",
      "\t\t\t\t\t\t(Died : 0.9, Survived : 0.1)\n",
      "\t\t\t\tembarked, 3.0\n",
      "\t\t\t\t\t\t(Died : 0.08, Survived : 0.92)\n",
      "\t\t\t\t\t\t(Died : 0.0, Survived : 1.0)\n",
      "\t\tcabin, 6.0\n",
      "\t\t\t\tage, 4.0\n",
      "\t\t\t\t\t\t(Died : 0.35714285714285715, Survived : 0.6428571428571429)\n",
      "\t\t\t\t\t\t(Died : 0.8651252408477842, Survived : 0.1348747591522158)\n",
      "\t\t\t\tage, 18.0\n",
      "\t\t\t\t\t\t(Died : 0.0, Survived : 1.0)\n",
      "\t\t\t\t\t\t(Died : 0.6605504587155964, Survived : 0.3394495412844037)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample visualization of Decision Tree structure\n",
    "titanic = DecisionTree(titanic_features, titanic_classes)\n",
    "titanic.fit(titanic_X, titanic_y, 3)\n",
    "print(titanic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will generate our predictions on a test set, and write them to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write our results to CSV file\n",
    "def results_to_csv(y_test, name):\n",
    "    y_test = y_test.astype(int)\n",
    "    df = pd.DataFrame({'Category': y_test})\n",
    "    df.index += 1 # Ensures that the index starts at 1. \n",
    "    csv_name = name + '.csv'\n",
    "    df.to_csv(csv_name, index_label='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit decision tree and random forest to both datasets, then generate predictions\n",
    "tree_t = DecisionTree(titanic_features, titanic_classes)\n",
    "tree_s = DecisionTree(spam_features, spam_classes)\n",
    "forest_t = RandomForest(titanic_features, titanic_classes, 10)\n",
    "forest_s = RandomForest(spam_features, spam_classes, 10)\n",
    "tree_t.fit(titanic_X,titanic_y, 10)\n",
    "tree_s.fit(spam_X,spam_y, 3)\n",
    "forest_t.fit(titanic_X, titanic_y, 3)\n",
    "forest_s.fit(spam_X, spam_y,3)\n",
    "titanic_test_tree = tree_t.predict(titanic_test)\n",
    "spam_test_tree = tree_s.predict(spam_test)\n",
    "titanic_test_forest = forest_t.predict(titanic_test)\n",
    "spam_test_forest = forest_s.predict(spam_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a CSV file for each set of predictions\n",
    "results_to_csv(titanic_test_tree, \"titanic_tree\")\n",
    "results_to_csv(spam_test_tree, \"spam_tree\")\n",
    "results_to_csv(spam_test_forest, \"spam_forest\")\n",
    "results_to_csv(titanic_test_forest, \"titanic_forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
